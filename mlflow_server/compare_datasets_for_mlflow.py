#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∑–∞–º–µ–Ω—ã –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è register_model_mlflow.py
–ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–ª—è –∑–∞–¥–∞—á MLflow —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
"""

import pandas as pd
import numpy as np
import yaml
import json
import os
import time
import pickle
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import xgboost as xgb
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

def load_config():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ config.yaml"""
    config_path = "../config.yaml"
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def prepare_data_for_mlflow(data_path, config):
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ç–æ—á–Ω–æ –∫–∞–∫ –≤ register_model_mlflow.py"""
    
    print(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç: {data_path}")
    df = pd.read_csv(data_path)
    
    # –ü–æ–ª—É—á–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    target_col = config['preprocessing']['features']['target_column']
    
    if target_col not in df.columns:
        raise ValueError(f"–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è '{target_col}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö")
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∏—Å–∫–ª—é—á–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é)
    feature_cols = [col for col in df.columns if col != target_col]
    X = df[feature_cols].copy()
    y = df[target_col].copy()
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º —Å–∫—Ä–∏–ø—Ç–µ)
    categorical_cols = X.select_dtypes(include=['object']).columns
    if len(categorical_cols) > 0:
        from sklearn.preprocessing import LabelEncoder
        for col in categorical_cols:
            le = LabelEncoder()
            X[col] = le.fit_transform(X[col].astype(str))
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
    if X.isnull().sum().sum() > 0:
        X = X.fillna(X.median())
    
    return X, y, df

def train_model_like_mlflow_script(X, y, config, dataset_name):
    """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å —Ç–æ—á–Ω–æ –∫–∞–∫ –≤ register_model_mlflow.py"""
    
    print(f"\nü§ñ –¢–†–ï–ù–ò–†–û–í–ö–ê –ú–û–î–ï–õ–ò –î–õ–Ø MLFLOW –†–ï–ì–ò–°–¢–†–ê–¶–ò–ò: {dataset_name}")
    print("=" * 60)
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º —Å–∫—Ä–∏–ø—Ç–µ)
    model_params = config.get('model', {}).get('params', {})
    random_state = config.get('model', {}).get('random_state', 42)
    test_size = config.get('model', {}).get('test_size', 0.2)
    
    # –î–æ–±–∞–≤–ª—è–µ–º random_state
    model_params['random_state'] = random_state
    
    print(f"üìä –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {X.shape[0]:,} –∑–∞–ø–∏—Å–µ–π")
    print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape[1]}")
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )
    
    print(f"üìä –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {X_train.shape[0]:,}")
    print(f"üìä –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {X_test.shape[0]:,}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    print(f"‚öôÔ∏è  –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏: {model_params}")
    model = xgb.XGBRegressor(**model_params)
    
    # –ó–∞–º–µ—Ä –≤—Ä–µ–º–µ–Ω–∏ –æ–±—É—á–µ–Ω–∏—è
    start_time = time.time()
    print("‚è≥ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    model.fit(X_train, y_train)
    training_time = time.time() - start_time
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred_train = model.predict(X_train)
    y_pred_test = model.predict(X_test)
    
    # –ú–µ—Ç—Ä–∏–∫–∏ (–∫–∞–∫ –≤ MLflow)
    metrics = {
        'train_mse': mean_squared_error(y_train, y_pred_train),
        'test_mse': mean_squared_error(y_test, y_pred_test),
        'train_rmse': np.sqrt(mean_squared_error(y_train, y_pred_train)),
        'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),
        'train_mae': mean_absolute_error(y_train, y_pred_train),
        'test_mae': mean_absolute_error(y_test, y_pred_test),
        'train_r2': r2_score(y_train, y_pred_train),
        'test_r2': r2_score(y_test, y_pred_test),
        'training_time': training_time
    }
    
    # –í—ã—á–∏—Å–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è MLflow –∞–Ω–∞–ª–∏–∑–∞
    overfit_ratio = metrics['train_rmse'] / metrics['test_rmse'] if metrics['test_rmse'] > 0 else 0
    metrics['overfitting_ratio'] = overfit_ratio
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è MLflow —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
    mlflow_info = {
        'model_size_mb': len(pickle.dumps(model)) / 1024 / 1024,
        'feature_count': X.shape[1],
        'training_samples': X_train.shape[0],
        'test_samples': X_test.shape[0],
        'feature_names': list(X.columns)
    }
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\nüìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–£–ß–ï–ù–ò–Ø:")
    print(f"   ‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {training_time:.2f} —Å–µ–∫")
    print(f"   üéØ Train RMSE: {metrics['train_rmse']:,.0f}")
    print(f"   üéØ Test RMSE:  {metrics['test_rmse']:,.0f}")
    print(f"   üìä Train R¬≤:   {metrics['train_r2']:.4f}")
    print(f"   üìä Test R¬≤:    {metrics['test_r2']:.4f}")
    print(f"   ‚öñÔ∏è  –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ: {overfit_ratio:.2f}x ({'üü¢ –ù–∏–∑–∫–æ–µ' if overfit_ratio < 1.2 else 'üü° –°—Ä–µ–¥–Ω–µ–µ' if overfit_ratio < 2.0 else 'üî¥ –í—ã—Å–æ–∫–æ–µ'})")
    
    return model, metrics, mlflow_info

def analyze_mlflow_compatibility(data_path, dataset_name):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å MLflow pipeline"""
    
    print(f"\nüîç –ê–ù–ê–õ–ò–ó –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò –° MLFLOW: {dataset_name}")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
    file_size_mb = os.path.getsize(data_path) / 1024 / 1024
    print(f"üìÅ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size_mb:.1f} MB")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    df = pd.read_csv(data_path)
    
    # –ê–Ω–∞–ª–∏–∑ –¥–ª—è MLflow
    mlflow_analysis = {
        'file_size_mb': file_size_mb,
        'memory_usage_mb': df.memory_usage(deep=True).sum() / 1024**2,
        'rows': df.shape[0],
        'columns': df.shape[1],
        'categorical_columns': len(df.select_dtypes(include=['object']).columns),
        'numeric_columns': len(df.select_dtypes(include=[np.number]).columns),
        'missing_values': df.isnull().sum().sum(),
        'target_range': (df['price'].min(), df['price'].max()) if 'price' in df.columns else (0, 0),
        'target_mean': df['price'].mean() if 'price' in df.columns else 0
    }
    
    print(f"üíæ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {mlflow_analysis['memory_usage_mb']:.1f} MB")
    print(f"üìä –ó–∞–ø–∏—Å–∏: {mlflow_analysis['rows']:,}")
    print(f"üìã –°—Ç–æ–ª–±—Ü—ã: {mlflow_analysis['columns']}")
    print(f"üéØ –î–∏–∞–ø–∞–∑–æ–Ω —Ü–µ–Ω: {mlflow_analysis['target_range'][0]:,.0f} - {mlflow_analysis['target_range'][1]:,.0f}")
    print(f"üìà –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞: {mlflow_analysis['target_mean']:,.0f}")
    
    # –û—Ü–µ–Ω–∫–∞ –≤–ª–∏—è–Ω–∏—è –Ω–∞ MLflow
    print(f"\nüìã –í–õ–ò–Ø–ù–ò–ï –ù–ê MLFLOW –ü–†–û–¶–ï–°–°–´:")
    
    # –í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    start_time = time.time()
    _ = pd.read_csv(data_path)
    load_time = time.time() - start_time
    print(f"   ‚è±Ô∏è  –í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏: {load_time:.2f} —Å–µ–∫")
    
    # –û—Ü–µ–Ω–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ MLflow
    estimated_model_size = mlflow_analysis['rows'] * mlflow_analysis['columns'] * 0.001  # –ø—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –≤ MB
    print(f"   üì¶ –û–∂–∏–¥–∞–µ–º—ã–π —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏: ~{estimated_model_size:.1f} MB")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è MLflow
    recommendations = []
    if file_size_mb > 50:
        recommendations.append("‚ö†Ô∏è  –ë–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ - —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —Å–∂–∞—Ç–∏–µ")
    if mlflow_analysis['rows'] > 500000:
        recommendations.append("‚ö†Ô∏è  –ú–Ω–æ–≥–æ –∑–∞–ø–∏—Å–µ–π - –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏")
    if mlflow_analysis['missing_values'] > 0:
        recommendations.append("‚ö†Ô∏è  –ï—Å—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è")
    
    if recommendations:
        print(f"\nüîß –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø MLFLOW:")
        for rec in recommendations:
            print(f"   {rec}")
    else:
        print(f"\n‚úÖ –û–ü–¢–ò–ú–ê–õ–¨–ù–û –î–õ–Ø MLFLOW")
    
    mlflow_analysis['load_time'] = load_time
    mlflow_analysis['estimated_model_size'] = estimated_model_size
    mlflow_analysis['recommendations'] = recommendations
    
    return mlflow_analysis

def compare_for_mlflow_registration(original_path, aligned_path, config):
    """–û—Å–Ω–æ–≤–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–ª—è MLflow —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏"""
    
    print("üÜö –°–†–ê–í–ù–ï–ù–ò–ï –î–ê–¢–ê–°–ï–¢–û–í –î–õ–Ø MLFLOW –†–ï–ì–ò–°–¢–†–ê–¶–ò–ò")
    print("=" * 70)
    
    results = {}
    
    # –ê–Ω–∞–ª–∏–∑ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    print("\nüîç –ê–ù–ê–õ–ò–ó –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò –° MLFLOW –ü–†–û–¶–ï–°–°–ê–ú–ò")
    results['original_mlflow'] = analyze_mlflow_compatibility(original_path, "–ò–°–•–û–î–ù–´–ô")
    results['aligned_mlflow'] = analyze_mlflow_compatibility(aligned_path, "–ü–†–ò–í–ï–î–ï–ù–ù–´–ô")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print(f"\nüìä –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –û–ë–£–ß–ï–ù–ò–Ø")
    X_orig, y_orig, df_orig = prepare_data_for_mlflow(original_path, config)
    X_aligned, y_aligned, df_aligned = prepare_data_for_mlflow(aligned_path, config)
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    model_orig, metrics_orig, mlflow_orig = train_model_like_mlflow_script(X_orig, y_orig, config, "–ò–°–•–û–î–ù–´–ô")
    model_aligned, metrics_aligned, mlflow_aligned = train_model_like_mlflow_script(X_aligned, y_aligned, config, "–ü–†–ò–í–ï–î–ï–ù–ù–´–ô")
    
    results['original_metrics'] = metrics_orig
    results['aligned_metrics'] = metrics_aligned
    results['original_mlflow_info'] = mlflow_orig
    results['aligned_mlflow_info'] = mlflow_aligned
    
    return results

def generate_mlflow_recommendation(results):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è MLflow —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏"""
    
    print(f"\nüéØ –ê–ù–ê–õ–ò–ó –≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–ò –î–õ–Ø REGISTER_MODEL_MLFLOW.PY")
    print("=" * 70)
    
    orig_metrics = results['original_metrics']
    aligned_metrics = results['aligned_metrics']
    orig_mlflow = results['original_mlflow']
    aligned_mlflow = results['aligned_mlflow']
    
    # –¢–∞–±–ª–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ –¥–ª—è MLflow
    print(f"\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –ö–õ–Æ–ß–ï–í–´–• –ú–ï–¢–†–ò–ö –î–õ–Ø MLFLOW:")
    print(f"{'–ú–µ—Ç—Ä–∏–∫–∞':<25} {'–ò—Å—Ö–æ–¥–Ω—ã–π':<15} {'–ü—Ä–∏–≤–µ–¥–µ–Ω–Ω—ã–π':<15} {'–ò–∑–º–µ–Ω–µ–Ω–∏–µ':<15}")
    print("-" * 75)
    
    key_metrics = [
        ('Test RMSE', 'test_rmse'),
        ('Test R¬≤', 'test_r2'),
        ('–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è (—Å–µ–∫)', 'training_time'),
        ('–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ (ratio)', 'overfitting_ratio')
    ]
    
    improvements = {}
    
    for display_name, metric_key in key_metrics:
        orig_val = orig_metrics[metric_key]
        aligned_val = aligned_metrics[metric_key]
        
        if metric_key in ['test_rmse', 'training_time', 'overfitting_ratio']:
            # –ú–µ–Ω—å—à–µ = –ª—É—á—à–µ
            change = ((orig_val - aligned_val) / orig_val) * 100
            is_better = aligned_val < orig_val
        else:
            # –ë–æ–ª—å—à–µ = –ª—É—á—à–µ
            change = ((aligned_val - orig_val) / abs(orig_val)) * 100
            is_better = aligned_val > orig_val
        
        improvements[metric_key] = change
        status = "üü¢" if is_better else "üî¥"
        
        print(f"{display_name:<25} {orig_val:<15.3f} {aligned_val:<15.3f} {status} {change:+.1f}%")
    
    # –ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –Ω–∞ MLflow –ø—Ä–æ—Ü–µ—Å—Å—ã
    print(f"\nüîß –í–õ–ò–Ø–ù–ò–ï –ù–ê MLFLOW –ü–†–û–¶–ï–°–°–´:")
    print(f"{'–ê—Å–ø–µ–∫—Ç':<25} {'–ò—Å—Ö–æ–¥–Ω—ã–π':<15} {'–ü—Ä–∏–≤–µ–¥–µ–Ω–Ω—ã–π':<15} {'–°—Ç–∞—Ç—É—Å'}")
    print("-" * 70)
    
    mlflow_aspects = [
        ('–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (MB)', orig_mlflow['file_size_mb'], aligned_mlflow['file_size_mb']),
        ('–í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏ (—Å–µ–∫)', orig_mlflow['load_time'], aligned_mlflow['load_time']),
        ('–ó–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è', orig_mlflow['training_samples'], aligned_mlflow['training_samples']),
        ('–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ (MB)', orig_mlflow['model_size_mb'], aligned_mlflow['model_size_mb'])
    ]
    
    for aspect, orig_val, aligned_val in mlflow_aspects:
        if aspect == '–ó–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è':
            status = "üü¢" if aligned_val > orig_val else "üî¥"
        else:
            status = "üü°" if abs(aligned_val - orig_val) / orig_val < 0.5 else "üî¥" if aligned_val > orig_val * 1.5 else "üü¢"
        
        print(f"{aspect:<25} {orig_val:<15.1f} {aligned_val:<15.1f} {status}")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è MLflow —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
    print(f"\nüéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø –î–õ–Ø REGISTER_MODEL_MLFLOW.PY:")
    
    # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏
    better_quality = improvements['test_r2'] > 5  # R¬≤ —É–ª—É—á—à–∏–ª—Å—è –Ω–∞ 5%+
    acceptable_rmse = improvements['test_rmse'] > -20  # RMSE —É—Ö—É–¥—à–∏–ª—Å—è –Ω–µ –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 20%
    no_severe_overfitting = aligned_metrics['overfitting_ratio'] < 3  # –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ–µ
    more_data = aligned_mlflow['training_samples'] > orig_mlflow['training_samples']
    
    criteria_met = sum([better_quality, acceptable_rmse, no_severe_overfitting, more_data])
    
    print(f"\nüìã –ö–†–ò–¢–ï–†–ò–ò –û–¶–ï–ù–ö–ò:")
    print(f"   {'‚úÖ' if better_quality else '‚ùå'} –ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ (R¬≤): {'–£–ª—É—á—à–∏–ª–æ—Å—å' if better_quality else '–ù–µ —É–ª—É—á—à–∏–ª–æ—Å—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ'}")
    print(f"   {'‚úÖ' if acceptable_rmse else '‚ùå'} –¢–æ—á–Ω–æ—Å—Ç—å (RMSE): {'–ü—Ä–∏–µ–º–ª–µ–º–æ' if acceptable_rmse else '–ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É—Ö—É–¥—à–∏–ª–∞—Å—å'}")
    print(f"   {'‚úÖ' if no_severe_overfitting else '‚ùå'} –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ: {'–ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ' if no_severe_overfitting else '–ö—Ä–∏—Ç–∏—á–Ω–æ–µ'}")
    print(f"   {'‚úÖ' if more_data else '‚ùå'} –û–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö: {'–£–≤–µ–ª–∏—á–∏–ª—Å—è' if more_data else '–û—Å—Ç–∞–ª—Å—è –ø—Ä–µ–∂–Ω–∏–º'}")
    
    if criteria_met >= 3:
        recommendation = "üü¢ –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø –ó–ê–ú–ï–ù–ê"
        reasoning = "–ü—Ä–∏–≤–µ–¥–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è MLflow —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏"
    elif criteria_met >= 2:
        recommendation = "üü° –£–°–õ–û–í–ù–ê–Ø –ó–ê–ú–ï–ù–ê"
        reasoning = "–ï—Å—Ç—å —É–ª—É—á—à–µ–Ω–∏—è, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏"
    else:
        recommendation = "üî¥ –ù–ï –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø –ó–ê–ú–ï–ù–ê"
        reasoning = "–ü—Ä–∏–≤–µ–¥–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤"
    
    print(f"\n{recommendation}")
    print(f"üìù –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: {reasoning}")
    print(f"üéØ –ö—Ä–∏—Ç–µ—Ä–∏–µ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: {criteria_met}/4")
    
    # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —à–∞–≥–∏ –¥–ª—è register_model_mlflow.py
    print(f"\nüîß –ö–û–ù–ö–†–ï–¢–ù–´–ï –®–ê–ì–ò –î–õ–Ø REGISTER_MODEL_MLFLOW.PY:")
    
    if "–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø" in recommendation:
        print(f"   1. ‚úÖ –û–±–Ω–æ–≤–∏—Ç—å config.yaml:")
        print(f"      initial_data: 'data/merged_data_improved_aligned.csv'")
        print(f"   2. ‚úÖ –ó–∞–ø—É—Å—Ç–∏—Ç—å register_model_mlflow.py")
        print(f"   3. ‚úÖ –°—Ä–∞–≤–Ω–∏—Ç—å –≤ MLflow UI —Å Run ID: a325fef21dad44c396b49a0b63cee154")
        print(f"   4. ‚úÖ –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
    else:
        print(f"   1. ‚ö†Ô∏è  –°–Ω–∞—á–∞–ª–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å:")
        print(f"      - –î–æ–±–∞–≤–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é (reg_alpha, reg_lambda)")
        print(f"      - –£–º–µ–Ω—å—à–∏—Ç—å max_depth –∏ —É–≤–µ–ª–∏—á–∏—Ç—å min_child_weight")
        print(f"   2. ‚ö†Ô∏è  –ó–∞—Ç–µ–º –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∞–Ω–∞–ª–∏–∑")
    
    return recommendation, criteria_met

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞"""
    
    # –ü—É—Ç–∏ –∫ –¥–∞—Ç–∞—Å–µ—Ç–∞–º
    original_path = "data/initial_data_set.csv"
    aligned_path = "data/merged_data_improved_aligned.csv"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤
    if not os.path.exists(original_path):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {original_path}")
        return
    
    if not os.path.exists(aligned_path):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {aligned_path}")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config = load_config()
    
    # –ü—Ä–æ–≤–æ–¥–∏–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
    results = compare_for_mlflow_registration(original_path, aligned_path, config)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
    recommendation, score = generate_mlflow_recommendation(results)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_results = {
        'timestamp': timestamp,
        'recommendation': recommendation,
        'score': f"{score}/4",
        'comparison_for': 'register_model_mlflow.py',
        'datasets': {
            'original': original_path,
            'aligned': aligned_path
        },
        'metrics': {
            'original': results['original_metrics'],
            'aligned': results['aligned_metrics']
        },
        'mlflow_impact': {
            'original': results['original_mlflow'],
            'aligned': results['aligned_mlflow']
        }
    }
    
    results_path = f"cv_results/mlflow_dataset_comparison_{timestamp}.json"
    os.makedirs("cv_results", exist_ok=True)
    
    with open(results_path, 'w', encoding='utf-8') as f:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π encoder –¥–ª—è numpy types
        json.dump(output_results, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_path}")
    
    return recommendation, results

if __name__ == "__main__":
    try:
        recommendation, results = main()
        print(f"\nüéâ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù")
        print(f"üéØ –ò–¢–û–ì–û–í–ê–Ø –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: {recommendation}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}")
        raise
