#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ Feature Selection
"""

# –ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
import xgboost as xgb
import yaml
import time
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
from mlxtend.feature_selection import SequentialFeatureSelector as SFS
from sklearn.metrics import mean_squared_error, r2_score

def load_config():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    with open('../config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    return config

def load_and_prepare_data():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –±–∞–∑–æ–≤–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
    print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è drop_columns
    config = load_config()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    df = pd.read_csv('data/initial_data_set.csv')
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {df.shape[0]} –∑–∞–ø–∏—Å–µ–π, {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")
    
    # –£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å–æ–≥–ª–∞—Å–Ω–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    drop_columns = config['preprocessing']['features']['drop_columns']
    print(f"üóëÔ∏è –£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å–æ–≥–ª–∞—Å–Ω–æ –∫–æ–Ω—Ñ–∏–≥—É: {drop_columns}")
    
    columns_to_drop = [col for col in drop_columns if col in df.columns]
    if columns_to_drop:
        df = df.drop(columns_to_drop, axis=1)
        print(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ –∫–æ–ª–æ–Ω–æ–∫: {columns_to_drop}")
    
    # –£–¥–∞–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª—É–∂–µ–±–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    if 'Unnamed: 0' in df.columns:
        df = df.drop('Unnamed: 0', axis=1)
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
    target_col = config['preprocessing']['features']['target_column']
    features = df.drop(target_col, axis=1)
    target = df[target_col]
    
    print(f"üéØ –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: {target_col}")
    print(f"üìù –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {features.shape[1]}")
    print(f"üìã –°–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {list(features.columns)}")
    
    return features, target

def create_manual_features(df):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ä—É—á–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫–∞–∫ –≤ Stage 3"""
    print("üîß –°–æ–∑–¥–∞–Ω–∏–µ —Ä—É—á–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    
    df = df.copy()
    
    # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è –ø–ª–æ—â–∞–¥–µ–π
    df['kitchen_to_total_ratio'] = df['kitchen_area'] / df['total_area']
    df['living_to_total_ratio'] = df['living_area'] / df['total_area']
    
    # –ü–ª–æ—â–∞–¥—å –Ω–∞ –∫–æ–º–Ω–∞—Ç—É
    df['area_per_room'] = df['total_area'] / df['rooms']
    
    # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —ç—Ç–∞–∂–µ–π
    df['floor_ratio'] = df['floor'] / df['floors_total']
    
    # –ö–≤–∞–¥—Ä–∞—Ç—ã –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    df['total_area_sq'] = df['total_area'] ** 2
    
    # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç —Ü–µ–Ω—Ç—Ä–∞ (–ø—Ä–∏–º–µ—Ä–Ω–æ–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
    # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ü–µ–Ω—Ç—Ä–∞ –ú–æ—Å–∫–≤—ã: ~55.7558, 37.6176
    moscow_center_lat = 55.7558
    moscow_center_lon = 37.6176
    
    df['distance_from_center'] = np.sqrt(
        (df['latitude'] - moscow_center_lat)**2 + 
        (df['longitude'] - moscow_center_lon)**2
    ) * 111  # –ø—Ä–∏–º–µ—Ä–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –≤ –∫–º
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(df.columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–≤–∫–ª—é—á–∞—è –Ω–æ–≤—ã–µ)")
    return df

def preprocess_features(features):
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    print("‚öôÔ∏è –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    
    features_processed = features.copy()
    
    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    categorical_features = ['building_type']
    
    for col in categorical_features:
        if col in features_processed.columns:
            le = LabelEncoder()
            features_processed[col] = le.fit_transform(features_processed[col].astype(str))
    
    # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –º–µ–¥–∏–∞–Ω–æ–π –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    numeric_features = features_processed.select_dtypes(include=[np.number]).columns
    for col in numeric_features:
        if features_processed[col].isnull().sum() > 0:
            median_val = features_processed[col].median()
            features_processed[col].fillna(median_val, inplace=True)
    
    print(f"‚úÖ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    return features_processed

def test_combined_feature_selection(X_train, X_test, y_train, y_test):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ Feature Selection"""
    print("\nüî¨ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ö–û–ú–ë–ò–ù–ò–†–û–í–ê–ù–ù–û–ì–û –ü–û–î–•–û–î–ê")
    print("=" * 60)
    
    start_time = time.time()
    
    # –≠—Ç–∞–ø 1: Feature Importance
    print("üìä –≠—Ç–∞–ø 1: Feature Importance –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
    
    base_model = xgb.XGBRegressor(
        n_estimators=300,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.9,
        colsample_bytree=0.8,
        random_state=42,
        n_jobs=1
    )
    
    print("‚è≥ –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    base_model.fit(X_train, y_train)
    
    # –ü–æ–ª—É—á–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    feature_importance = base_model.feature_importances_
    feature_names = X_train.columns
    importance_df = pd.DataFrame({
        'feature': feature_names,
        'importance': feature_importance
    }).sort_values('importance', ascending=False)
    
    # –û—Ç–±–∏—Ä–∞–µ–º —Ç–æ–ø-20 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    top_20_features = importance_df.head(20)['feature'].tolist()
    print(f"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ {len(top_20_features)} –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏")
    
    print("üîù –¢–æ–ø-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏:")
    for i, row in importance_df.head(10).iterrows():
        print(f"   {row.name+1:2d}. {row['feature']:25s} {row['importance']:.4f}")
    
    # –≠—Ç–∞–ø 2: SFS –≤–Ω—É—Ç—Ä–∏ —Ç–æ–ø-20
    print(f"\nüìä –≠—Ç–∞–ø 2: Sequential Feature Selection –≤–Ω—É—Ç—Ä–∏ —Ç–æ–ø-{len(top_20_features)}")
    print("‚öôÔ∏è –¶–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: 16 (–ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤)")
    
    X_train_top20 = X_train[top_20_features]
    X_test_top20 = X_test[top_20_features]
    
    # SFS –º–æ–¥–µ–ª—å
    sfs_model = xgb.XGBRegressor(
        n_estimators=300,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.9,
        colsample_bytree=0.8,
        random_state=42,
        n_jobs=1
    )
    
    sfs = SFS(
        sfs_model,
        k_features=16,
        forward=True,
        floating=False,
        scoring='neg_root_mean_squared_error',
        cv=3,
        n_jobs=1
    )
    
    print("‚è≥ –ó–∞–ø—É—Å–∫ Sequential Feature Selection...")
    sfs_start = time.time()
    sfs = sfs.fit(X_train_top20, y_train)
    sfs_time = time.time() - sfs_start
    
    # –ü–æ–ª—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    selected_features = list(sfs.k_feature_names_)
    
    print(f"‚úÖ SFS –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {sfs_time:.1f} —Å–µ–∫—É–Ω–¥")
    print(f"üìä –í—ã–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(selected_features)}")
    print(f"üéØ –í—ã–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:")
    for i, feature in enumerate(selected_features, 1):
        print(f"   {i:2d}. {feature}")
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
    print(f"\nüìà –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏...")
    
    final_model = xgb.XGBRegressor(
        n_estimators=300,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.9,
        colsample_bytree=0.8,
        random_state=42,
        n_jobs=1
    )
    
    X_train_selected = X_train[selected_features]
    X_test_selected = X_test[selected_features]
    
    # –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
    final_model.fit(X_train_selected, y_train)
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred_train = final_model.predict(X_train_selected)
    y_pred_test = final_model.predict(X_test_selected)
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
    train_r2 = r2_score(y_train, y_pred_train)
    test_r2 = r2_score(y_test, y_pred_test)
    
    # Cross-validation
    cv_scores = cross_val_score(final_model, X_train_selected, y_train, 
                               cv=3, scoring='neg_root_mean_squared_error', n_jobs=1)
    cv_rmse = -cv_scores.mean()
    
    total_time = time.time() - start_time
    
    print(f"\nüéØ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ö–û–ú–ë–ò–ù–ò–†–û–í–ê–ù–ù–û–ì–û –ü–û–î–•–û–î–ê:")
    print(f"   ‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.1f} —Å–µ–∫—É–Ω–¥")
    print(f"   üìä –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(selected_features)} (–∏–∑ {X_train.shape[1]})")
    print(f"   üéØ Train RMSE: {train_rmse:,.0f} —Ä—É–±.")
    print(f"   üéØ Test RMSE:  {test_rmse:,.0f} —Ä—É–±.")
    print(f"   üìà Train R¬≤:   {train_r2:.4f}")
    print(f"   üìà Test R¬≤:    {test_r2:.4f}")
    print(f"   üîÑ CV RMSE:    {cv_rmse:,.0f} —Ä—É–±.")
    
    return {
        'selected_features': selected_features,
        'test_rmse': test_rmse,
        'test_r2': test_r2,
        'cv_rmse': cv_rmse,
        'execution_time': total_time,
        'n_features': len(selected_features)
    }

def test_baseline_comparison(X_train, X_test, y_train, y_test):
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å baseline (–≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏)"""
    print("\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –° BASELINE (–≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏)")
    print("=" * 50)
    
    baseline_model = xgb.XGBRegressor(
        n_estimators=300,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.9,
        colsample_bytree=0.8,
        random_state=42,
        n_jobs=1
    )
    
    start_time = time.time()
    baseline_model.fit(X_train, y_train)
    y_pred_baseline = baseline_model.predict(X_test)
    baseline_time = time.time() - start_time
    
    baseline_rmse = np.sqrt(mean_squared_error(y_test, y_pred_baseline))
    baseline_r2 = r2_score(y_test, y_pred_baseline)
    
    cv_scores_baseline = cross_val_score(baseline_model, X_train, y_train, 
                                        cv=3, scoring='neg_root_mean_squared_error', n_jobs=1)
    cv_rmse_baseline = -cv_scores_baseline.mean()
    
    print(f"üéØ BASELINE –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print(f"   ‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {baseline_time:.1f} —Å–µ–∫—É–Ω–¥")
    print(f"   üìä –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {X_train.shape[1]}")
    print(f"   üéØ Test RMSE: {baseline_rmse:,.0f} —Ä—É–±.")
    print(f"   üìà Test R¬≤:   {baseline_r2:.4f}")
    print(f"   üîÑ CV RMSE:   {cv_rmse_baseline:,.0f} —Ä—É–±.")
    
    return {
        'test_rmse': baseline_rmse,
        'test_r2': baseline_r2,
        'cv_rmse': cv_rmse_baseline,
        'execution_time': baseline_time,
        'n_features': X_train.shape[1]
    }

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ö–û–ú–ë–ò–ù–ò–†–û–í–ê–ù–ù–û–ì–û FEATURE SELECTION")
    print("=" * 80)
    
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        config = load_config()
        print("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        features, target = load_and_prepare_data()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä—É—á–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        features_enhanced = create_manual_features(features)
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        features_processed = preprocess_features(features_enhanced)
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
        X_train, X_test, y_train, y_test = train_test_split(
            features_processed, target, 
            test_size=0.2, 
            random_state=42
        )
        
        print(f"\nüìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:")
        print(f"   üéØ Train: {X_train.shape[0]} –æ–±—Ä–∞–∑—Ü–æ–≤")
        print(f"   üéØ Test:  {X_test.shape[0]} –æ–±—Ä–∞–∑—Ü–æ–≤")
        print(f"   üìù –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {X_train.shape[1]}")
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ baseline
        baseline_results = test_baseline_comparison(X_train, X_test, y_train, y_test)
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞
        combined_results = test_combined_feature_selection(X_train, X_test, y_train, y_test)
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print(f"\nüèÜ –°–†–ê–í–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
        print("=" * 80)
        
        rmse_improvement = (baseline_results['test_rmse'] - combined_results['test_rmse']) / baseline_results['test_rmse'] * 100
        r2_improvement = (combined_results['test_r2'] - baseline_results['test_r2']) / baseline_results['test_r2'] * 100
        feature_reduction = (baseline_results['n_features'] - combined_results['n_features']) / baseline_results['n_features'] * 100
        
        print(f"üìä BASELINE:           RMSE={baseline_results['test_rmse']:,.0f}, R¬≤={baseline_results['test_r2']:.4f}, –ü—Ä–∏–∑–Ω–∞–∫–æ–≤={baseline_results['n_features']}")
        print(f"üî¨ –ö–û–ú–ë–ò–ù–ò–†–û–í–ê–ù–ù–´–ô:    RMSE={combined_results['test_rmse']:,.0f}, R¬≤={combined_results['test_r2']:.4f}, –ü—Ä–∏–∑–Ω–∞–∫–æ–≤={combined_results['n_features']}")
        print(f"")
        print(f"üìà –£–ª—É—á—à–µ–Ω–∏–µ RMSE:     {rmse_improvement:+.2f}% ({'‚úÖ –£–õ–£–ß–®–ï–ù–ò–ï' if rmse_improvement > 0 else '‚ùå –£–•–£–î–®–ï–ù–ò–ï'})")
        print(f"üìà –£–ª—É—á—à–µ–Ω–∏–µ R¬≤:       {r2_improvement:+.2f}% ({'‚úÖ –£–õ–£–ß–®–ï–ù–ò–ï' if r2_improvement > 0 else '‚ùå –£–•–£–î–®–ï–ù–ò–ï'})")
        print(f"üìâ –°–æ–∫—Ä–∞—â–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {feature_reduction:.1f}% ({'‚úÖ –°–û–ö–†–ê–©–ï–ù–ò–ï' if feature_reduction > 0 else '‚ö†Ô∏è –£–í–ï–õ–ò–ß–ï–ù–ò–ï'})")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –æ–∂–∏–¥–∞–Ω–∏—è–º –∏–∑ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
        print(f"\nüéØ –ü–†–û–í–ï–†–ö–ê –û–ñ–ò–î–ê–ù–ò–ô –ò–ó –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–û–í:")
        if rmse_improvement > 0.3:  # –û–∂–∏–¥–∞–ª–∏ +0.53%
            print(f"‚úÖ RMSE —É–ª—É—á—à–µ–Ω–∏–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–∂–∏–¥–∞–Ω–∏—è–º ({rmse_improvement:.2f}% > 0.3%)")
        else:
            print(f"‚ö†Ô∏è RMSE —É–ª—É—á—à–µ–Ω–∏–µ –Ω–∏–∂–µ –æ–∂–∏–¥–∞–Ω–∏–π ({rmse_improvement:.2f}% < 0.3%)")
            
        if combined_results['n_features'] == 16:
            print(f"‚úÖ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–∂–∏–¥–∞–Ω–∏—è–º (16)")
        else:
            print(f"‚ö†Ô∏è –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –æ–∂–∏–¥–∞–Ω–∏–π ({combined_results['n_features']} != 16)")
        
        print(f"\nüéâ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
