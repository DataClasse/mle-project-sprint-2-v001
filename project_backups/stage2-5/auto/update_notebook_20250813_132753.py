#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–æ—É—Ç–±—É–∫–∞: –∑–∞–º–µ–Ω–∞ –ø—Ä–æ—Å—Ç–æ–≥–æ SFS –Ω–∞ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥
"""

import json
import sys

def update_notebook():
    """–û–±–Ω–æ–≤–ª—è–µ—Ç –Ω–æ—É—Ç–±—É–∫, –∑–∞–º–µ–Ω—è—è SFS –∫–æ–¥ –Ω–∞ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥"""
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ—É—Ç–±—É–∫
    with open('improve_baseline_model.ipynb', 'r', encoding='utf-8') as f:
        notebook = json.load(f)
    
    # –ò—â–µ–º —è—á–µ–π–∫—É —Å SFS –∫–æ–¥–æ–º
    sfs_cell_idx = None
    for i, cell in enumerate(notebook['cells']):
        if cell['cell_type'] == 'code' and cell['source']:
            source_text = ''.join(cell['source'])
            if 'Sequential Forward Selection —Å XGBoost' in source_text and 'k_features=5' in source_text:
                sfs_cell_idx = i
                break
    
    if sfs_cell_idx is None:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–∞ —è—á–µ–π–∫–∞ —Å SFS –∫–æ–¥–æ–º")
        return False
    
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ SFS —è—á–µ–π–∫–∞: –∏–Ω–¥–µ–∫—Å {sfs_cell_idx}")
    
    # –ù–æ–≤—ã–π –∫–æ–¥ –¥–ª—è –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞
    new_code = [
        "%%time\n",
        "\n",
        "# üî¨ –ö–û–ú–ë–ò–ù–ò–†–û–í–ê–ù–ù–´–ô –ü–û–î–•–û–î: Feature Importance + SFS\n",
        "# –ù–∞ –æ—Å–Ω–æ–≤–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∫–∞–∫ –Ω–∞–∏–±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥\n",
        "print(\"üîç –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ Feature Selection —Å XGBoost\")\n",
        "print(\"üìä –≠—Ç–∞–ø 1: Feature Importance –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏\")\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "base_model = xgb.XGBRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=1\n",
        ")\n",
        "\n",
        "# –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –∏ –ø–æ–ª—É—á–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å\n",
        "print(\"‚è≥ –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...\")\n",
        "base_model.fit(features_train_top10, target_train)\n",
        "\n",
        "# –ü–æ–ª—É—á–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "feature_importance = base_model.feature_importances_\n",
        "feature_names = features_train_top10.columns\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': feature_importance\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "# –û—Ç–±–∏—Ä–∞–µ–º —Ç–æ–ø-20 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ SFS\n",
        "top_20_features = importance_df.head(20)['feature'].tolist()\n",
        "print(f\"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ {len(top_20_features)} –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏\")\n",
        "\n",
        "# –≠—Ç–∞–ø 2: SFS –≤–Ω—É—Ç—Ä–∏ —Ç–æ–ø-20 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "print(\"\\nüìä –≠—Ç–∞–ø 2: Sequential Feature Selection –≤–Ω—É—Ç—Ä–∏ —Ç–æ–ø-20\")\n",
        "print(\"‚öôÔ∏è –¶–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: 16 (–ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤)\")\n",
        "\n",
        "# –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ —Å —Ç–æ–ø-20 –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏\n",
        "X_train_top20 = features_train_top10[top_20_features]\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º SFS –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö 16 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "sfs_model = xgb.XGBRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=1\n",
        ")\n",
        "\n",
        "sfs = SFS(\n",
        "    sfs_model,\n",
        "    k_features=16,  # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –ø–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º\n",
        "    forward=True,\n",
        "    floating=False,\n",
        "    scoring='neg_root_mean_squared_error',\n",
        "    cv=3,\n",
        "    n_jobs=1\n",
        ")\n",
        "\n",
        "print(\"‚è≥ –ó–∞–ø—É—Å–∫ Sequential Feature Selection...\")\n",
        "sfs = sfs.fit(X_train_top20, target_train)\n",
        "\n",
        "# –ü–æ–ª—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "selected_features = list(sfs.k_feature_names_)\n",
        "\n",
        "print(f\"‚úÖ –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω!\")\n",
        "print(f\"üìä –í—ã–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(selected_features)}\")\n",
        "print(f\"üéØ –í—ã–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:\")\n",
        "for i, feature in enumerate(selected_features, 1):\n",
        "    print(f\"   {i:2d}. {feature}\")\n",
        "\n",
        "# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã SFS –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\n",
        "sfs_df = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
        "display(sfs_df)"
    ]
    
    # –ó–∞–º–µ–Ω—è–µ–º –∫–æ–¥ –≤ –Ω–∞–π–¥–µ–Ω–Ω–æ–π —è—á–µ–π–∫–µ
    notebook['cells'][sfs_cell_idx]['source'] = new_code
    
    # –¢–µ–ø–µ—Ä—å –∏—â–µ–º –∏ —É–¥–∞–ª—è–µ–º —è—á–µ–π–∫–∏ —Å SBS –∏ union logic
    cells_to_remove = []
    
    for i, cell in enumerate(notebook['cells']):
        if cell['cell_type'] == 'code' and cell['source']:
            source_text = ''.join(cell['source'])
            # –ò—â–µ–º —è—á–µ–π–∫–∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å SBS –∏–ª–∏ union features
            if any(keyword in source_text for keyword in [
                'Sequential Backward Selection',
                'sbs = SFS(',
                'top_sbs =',
                'union_features =',
                'interc_features ='
            ]):
                cells_to_remove.append(i)
    
    # –£–¥–∞–ª—è–µ–º —è—á–µ–π–∫–∏ –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ (—á—Ç–æ–±—ã –∏–Ω–¥–µ–∫—Å—ã –Ω–µ —Å–º–µ—Å—Ç–∏–ª–∏—Å—å)
    for i in reversed(cells_to_remove):
        print(f"üóëÔ∏è –£–¥–∞–ª—è–µ–º —è—á–µ–π–∫—É {i}: SBS/Union –∫–æ–¥")
        del notebook['cells'][i]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é —è—á–µ–π–∫—É –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è selected_features
    new_final_cell = {
        "cell_type": "code",
        "execution_count": None,
        "id": "final_selected_features",
        "metadata": {},
        "outputs": [],
        "source": [
            "# –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞\n",
            "features_selected = selected_features\n",
            "print(f\"‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(features_selected)}\")\n",
            "print(features_selected)"
        ]
    }
    
    # –ù–∞—Ö–æ–¥–∏–º –ø–æ–∑–∏—Ü–∏—é –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ (–ø–æ—Å–ª–µ SFS —è—á–µ–π–∫–∏)
    insert_position = sfs_cell_idx + 1
    notebook['cells'].insert(insert_position, new_final_cell)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –Ω–æ—É—Ç–±—É–∫
    with open('improve_baseline_model.ipynb', 'w', encoding='utf-8') as f:
        json.dump(notebook, f, ensure_ascii=False, indent=1)
    
    print("‚úÖ –ù–æ—É—Ç–±—É–∫ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω!")
    print(f"üìù –ó–∞–º–µ–Ω–µ–Ω–∞ —è—á–µ–π–∫–∞ {sfs_cell_idx} –Ω–∞ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥")
    print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {len(cells_to_remove)} —è—á–µ–µ–∫ —Å —É—Å—Ç–∞—Ä–µ–≤—à–∏–º –∫–æ–¥–æ–º")
    print("üìä –î–æ–±–∞–≤–ª–µ–Ω–∞ —è—á–µ–π–∫–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏")
    
    return True

if __name__ == "__main__":
    update_notebook()
