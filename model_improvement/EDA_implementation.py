#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–≠—Ç–∞–ø 2: –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö (EDA)
–ü—Ä–æ–µ–∫—Ç: –£–ª—É—á—à–µ–Ω–∏–µ baseline-–º–æ–¥–µ–ª–∏ –¥–ª—è –Ø–Ω–¥–µ–∫—Å –ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞:
1. –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ Jupyter Notebook, –∏—Å–ø–æ–ª—å–∑—É—è –±–∏–±–ª–∏–æ—Ç–µ–∫—É pandas
2. –ü—Ä–æ–≤–µ—Å—Ç–∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö (–ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∏–ø–æ–≤)
3. –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é matplotlib –∏ seaborn
4. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
5. –°–æ–∑–¥–∞—Ç—å markdown-—è—á–µ–π–∫—É —Å –º–∏–Ω–∏–º—É–º 3 –∫–ª—é—á–µ–≤—ã–º–∏ –≤—ã–≤–æ–¥–∞–º–∏
6. –ó–∞–ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –≤ MLflow Jupyter Notebook –∏ markdown-—Ñ–∞–π–ª —Å –≤—ã–≤–æ–¥–∞–º–∏
"""

import os
import warnings
import yaml
import json
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial Unicode MS', 'SimHei']
warnings.filterwarnings("ignore")

class EDAAnalyzer:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, data_path, config_path="../config.yaml"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        
        Args:
            data_path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–∞–Ω–Ω—ã—Ö
            config_path (str): –ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        self.data_path = data_path
        self.config_path = config_path
        self.df = None
        self.config = None
        self.target_column = None
        self.drop_columns = None
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        self._load_config()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        self._setup_display()
        
    def _load_config(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ YAML —Ñ–∞–π–ª–∞"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f)
            
            self.target_column = self.config['preprocessing']['features']['target_column']
            self.drop_columns = self.config['preprocessing']['features']['drop_columns']
            print("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
            # –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            self.target_column = 'price'
            self.drop_columns = ['id', 'building_id']
    
    def _setup_display(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        pd.options.display.max_columns = 100
        pd.options.display.max_rows = 64
        sns.set_theme(style="ticks", palette="pastel")
        plt.style.use('seaborn-v0_8')
    
    def load_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        print("ÔøΩÔøΩ –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•...")
        print("=" * 50)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        if not os.path.exists(self.data_path):
            raise FileNotFoundError(f"–§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.data_path}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π —Ç–∏–ø–æ–≤
        try:
            self.df = pd.read_csv(self.data_path, dtype={
                "rooms": "category",
                "building_type": "category",
                "floor": "int16",
                "floors_total": "int16",
                "flats_count": "int32",
                "build_year": "int16",
                "is_apartment": "bool",
                "studio": "bool",
                "has_elevator": "bool"
            })
            
            print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
            print(f"   –†–∞–∑–º–µ—Ä: {self.df.shape[0]:,} —Å—Ç—Ä–æ–∫ √ó {self.df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")
            print(f"   –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {self.df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
            raise
        
        # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
        columns_to_drop = list(set(self.df.columns) & set(self.drop_columns))
        if columns_to_drop:
            self.df.drop(columns=columns_to_drop, axis=1, inplace=True)
            print(f"   –£–¥–∞–ª–µ–Ω—ã —Å—Ç–æ–ª–±—Ü—ã: {columns_to_drop}")
            print(f"   –ù–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä: {self.df.shape[0]:,} —Å—Ç—Ä–æ–∫ √ó {self.df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")
        
        return self.df
    
    def basic_data_analysis(self):
        """–ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö"""
        print("\nÔøΩÔøΩ –ë–ê–ó–û–í–´–ô –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•")
        print("=" * 50)
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö
        print("ÔøΩÔøΩ –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –î–ê–ù–ù–´–•:")
        print(self.df.info())
        
        print("\nÔøΩÔøΩ –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–û–ï –û–ü–ò–°–ê–ù–ò–ï:")
        print(self.df.describe())
        
        print("\nüî¢ –¢–ò–ü–´ –î–ê–ù–ù–´–•:")
        print(self.df.dtypes.value_counts())
        
        print("\n‚ùì –ü–†–û–ü–£–©–ï–ù–ù–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø:")
        missing_data = self.df.isnull().sum()
        if missing_data.sum() > 0:
            missing_percent = (missing_data / len(self.df)) * 100
            missing_df = pd.DataFrame({
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': missing_data,
                '–ü—Ä–æ—Ü–µ–Ω—Ç': missing_percent
            }).sort_values('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', ascending=False)
            print(missing_df[missing_df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'] > 0])
        else:
            print("‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ—Ç")
        
        print("\nÔøΩÔøΩ –ü–ï–†–í–´–ï 5 –°–¢–†–û–ö:")
        print(self.df.head())
        
        print("\nüîç –ü–û–°–õ–ï–î–ù–ò–ï 5 –°–¢–†–û–ö:")
        print(self.df.tail())
    
    def numerical_features_analysis(self):
        """–ê–Ω–∞–ª–∏–∑ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        print("\nüî¢ –ê–ù–ê–õ–ò–ó –ß–ò–°–õ–û–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í")
        print("=" * 50)
        
        # –ü–æ–ª—É—á–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        numerical_features = self.config['preprocessing']['features'].get('numerical_features', [])
        
        if not numerical_features:
            # –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã –≤ –∫–æ–Ω—Ñ–∏–≥–µ, –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            numerical_features = self.df.select_dtypes(include=[np.number]).columns.tolist()
            numerical_features = [col for col in numerical_features if col != self.target_column]
        
        print(f"ÔøΩÔøΩ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(numerical_features)} —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        
        for feature in numerical_features:
            if feature in self.df.columns:
                print(f"\nÔøΩÔøΩ {feature.upper()}:")
                print(f"   –¢–∏–ø: {self.df[feature].dtype}")
                print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {self.df[feature].nunique()}")
                print(f"   –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {self.df[feature].isnull().sum()}")
                print(f"   –ú–∏–Ω–∏–º—É–º: {self.df[feature].min()}")
                print(f"   –ú–∞–∫—Å–∏–º—É–º: {self.df[feature].max()}")
                print(f"   –°—Ä–µ–¥–Ω–µ–µ: {self.df[feature].mean():.2f}")
                print(f"   –ú–µ–¥–∏–∞–Ω–∞: {self.df[feature].median():.2f}")
                print(f"   –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {self.df[feature].std():.2f}")
                print(f"   –ö–≤–∞—Ä—Ç–∏–ª–∏: {self.df[feature].quantile([0.25, 0.5, 0.75]).tolist()}")
    
    def categorical_features_analysis(self):
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        print("\nüè∑Ô∏è –ê–ù–ê–õ–ò–ó –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í")
        print("=" * 50)
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        categorical_features = self.config['preprocessing']['features'].get('categorical_numeric_features', [])
        
        if not categorical_features:
            # –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã –≤ –∫–æ–Ω—Ñ–∏–≥–µ, –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            categorical_features = self.df.select_dtypes(include=['category', 'object']).columns.tolist()
        
        print(f"ÔøΩÔøΩ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(categorical_features)} –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        
        for feature in categorical_features:
            if feature in self.df.columns:
                print(f"\nÔøΩÔøΩ {feature.upper()}:")
                print(f"   –¢–∏–ø: {self.df[feature].dtype}")
                print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {self.df[feature].nunique()}")
                print(f"   –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {self.df[feature].isnull().sum()}")
                print(f"   –¢–æ–ø-10 –∑–Ω–∞—á–µ–Ω–∏–π:")
                value_counts = self.df[feature].value_counts().head(10)
                for value, count in value_counts.items():
                    percentage = (count / len(self.df)) * 100
                    print(f"     {value}: {count:,} ({percentage:.1f}%)")
    
    def boolean_features_analysis(self):
        """–ê–Ω–∞–ª–∏–∑ –±—É–ª–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        print("\n‚úÖ –ê–ù–ê–õ–ò–ó –ë–£–õ–ï–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í")
        print("=" * 50)
        
        # –ü–æ–ª—É—á–∞–µ–º –±—É–ª–µ–≤—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        boolean_features = self.config['preprocessing']['features'].get('boolean_features', [])
        
        if not boolean_features:
            # –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã –≤ –∫–æ–Ω—Ñ–∏–≥–µ, –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            boolean_features = self.df.select_dtypes(include=['bool']).columns.tolist()
        
        print(f"üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(boolean_features)} –±—É–ª–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        
        for feature in boolean_features:
            if feature in self.df.columns:
                print(f"\nÔøΩÔøΩ {feature.upper()}:")
                print(f"   –¢–∏–ø: {self.df[feature].dtype}")
                print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {self.df[feature].nunique()}")
                print(f"   –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {self.df[feature].isnull().sum()}")
                print(f"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:")
                value_counts = self.df[feature].value_counts()
                for value, count in value_counts.items():
                    percentage = (count / len(self.df)) * 100
                    print(f"     {value}: {count:,} ({percentage:.1f}%)")
    
    def target_analysis(self):
        """–ê–Ω–∞–ª–∏–∑ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π"""
        print("\nüéØ –ê–ù–ê–õ–ò–ó –¶–ï–õ–ï–í–û–ô –ü–ï–†–ï–ú–ï–ù–ù–û–ô")
        print("=" * 50)
        
        target = self.df[self.target_column]
        
        print(f"üìä {self.target_column.upper()}:")
        print(f"   –¢–∏–ø: {target.dtype}")
        print(f"   –†–∞–∑–º–µ—Ä: {len(target):,}")
        print(f"   –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {target.isnull().sum()}")
        print(f"   –ú–∏–Ω–∏–º—É–º: {target.min():,.0f}")
        print(f"   –ú–∞–∫—Å–∏–º—É–º: {target.max():,.0f}")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ: {target.mean():,.0f}")
        print(f"   –ú–µ–¥–∏–∞–Ω–∞: {target.median():,.0f}")
        print(f"   –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {target.std():,.0f}")
        print(f"   –ö–≤–∞—Ä—Ç–∏–ª–∏: {target.quantile([0.25, 0.5, 0.75]).tolist()}")
        
        # –ê–Ω–∞–ª–∏–∑ –≤—ã–±—Ä–æ—Å–æ–≤
        Q1 = target.quantile(0.25)
        Q3 = target.quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = target[(target < lower_bound) | (target > upper_bound)]
        print(f"   –í—ã–±—Ä–æ—Å—ã (IQR –º–µ—Ç–æ–¥): {len(outliers):,} ({len(outliers)/len(target)*100:.1f}%)")
        print(f"   –ì—Ä–∞–Ω–∏—Ü—ã –≤—ã–±—Ä–æ—Å–æ–≤: [{lower_bound:,.0f}, {upper_bound:,.0f}]")
    
    def create_visualizations(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π"""
        print("\nÔøΩÔøΩ –°–û–ó–î–ê–ù–ò–ï –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ô")
        print("=" * 50)
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
        plots_dir = Path("plots")
        plots_dir.mkdir(exist_ok=True)
        
        # 1. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        self._plot_target_distribution(plots_dir)
        
        # 2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        self._plot_numerical_distributions(plots_dir)
        
        # 3. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        self._plot_categorical_distributions(plots_dir)
        
        # 4. –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
        self._plot_correlation_matrix(plots_dir)
        
        # 5. –í–∑–∞–∏–º–æ—Å–≤—è–∑—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        self._plot_feature_target_relationships(plots_dir)
        
        print(f"‚úÖ –ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫—É: {plots_dir}")
    
    def _plot_target_distribution(self, plots_dir):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        target = self.df[self.target_column]
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞
        sns.histplot(data=self.df, x=self.target_column, kde=True, ax=axes[0, 0])
        axes[0, 0].set_title(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {self.target_column}")
        axes[0, 0].set_xlabel(self.target_column)
        axes[0, 0].set_ylabel("–ß–∞—Å—Ç–æ—Ç–∞")
        
        # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞
        log_target = np.log1p(target)
        sns.histplot(data=log_target, kde=True, ax=axes[0, 1])
        axes[0, 1].set_title(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ log({self.target_column} + 1)")
        axes[0, 1].set_xlabel(f"log({self.target_column} + 1)")
        axes[0, 1].set_ylabel("–ß–∞—Å—Ç–æ—Ç–∞")
        
        # Box plot
        sns.boxplot(data=self.df, x=self.target_column, ax=axes[1, 0])
        axes[1, 0].set_title(f"Box plot {self.target_column}")
        axes[1, 0].set_xlabel(self.target_column)
        
        # Q-Q plot
        from scipy import stats
        stats.probplot(target, dist="norm", plot=axes[1, 1])
        axes[1, 1].set_title("Q-Q Plot (–Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)")
        
        plt.tight_layout()
        plt.savefig(plots_dir / "target_distribution.png", dpi=300, bbox_inches='tight')
        plt.show()
    
    def _plot_numerical_distributions(self, plots_dir):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        numerical_features = self.config['preprocessing']['features'].get('numerical_features', [])
        
        if not numerical_features:
            numerical_features = self.df.select_dtypes(include=[np.number]).columns.tolist()
            numerical_features = [col for col in numerical_features if col != self.target_column]
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥—Ä–∞—Ñ–∏–∫–æ–≤
        features_to_plot = numerical_features[:6]
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        axes = axes.ravel()
        
        for i, feature in enumerate(features_to_plot):
            if feature in self.df.columns:
                sns.histplot(data=self.df, x=feature, kde=True, ax=axes[i])
                axes[i].set_title(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {feature}")
                axes[i].set_xlabel(feature)
                axes[i].set_ylabel("–ß–∞—Å—Ç–æ—Ç–∞")
        
        # –°–∫—Ä—ã–≤–∞–µ–º –ª–∏—à–Ω–∏–µ –æ—Å–∏
        for i in range(len(features_to_plot), len(axes)):
            axes[i].set_visible(False)
        
        plt.tight_layout()
        plt.savefig(plots_dir / "numerical_distributions.png", dpi=300, bbox_inches='tight')
        plt.show()
    
    def _plot_categorical_distributions(self, plots_dir):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        categorical_features = self.config['preprocessing']['features'].get('categorical_numeric_features', [])
        
        if not categorical_features:
            categorical_features = self.df.select_dtypes(include=['category', 'object']).columns.tolist()
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥—Ä–∞—Ñ–∏–∫–æ–≤
        features_to_plot = categorical_features[:4]
        
        if len(features_to_plot) > 0:
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            axes = axes.ravel()
            
            for i, feature in enumerate(features_to_plot):
                if feature in self.df.columns:
                    sns.countplot(data=self.df, x=feature, ax=axes[i])
                    axes[i].set_title(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {feature}")
                    axes[i].set_xlabel(feature)
                    axes[i].set_ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")
                    axes[i].tick_params(axis='x', rotation=45)
            
            # –°–∫—Ä—ã–≤–∞–µ–º –ª–∏—à–Ω–∏–µ –æ—Å–∏
            for i in range(len(features_to_plot), len(axes)):
                axes[i].set_visible(False)
            
            plt.tight_layout()
            plt.savefig(plots_dir / "categorical_distributions.png", dpi=300, bbox_inches='tight')
            plt.show()
    
    def _plot_correlation_matrix(self, plots_dir):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã"""
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        numerical_df = self.df.select_dtypes(include=[np.number])
        
        if len(numerical_df.columns) > 1:
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É
            corr_matrix = numerical_df.corr()
            
            # –°–æ–∑–¥–∞–µ–º —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É
            plt.figure(figsize=(12, 10))
            mask = np.zeros_like(corr_matrix)
            mask[np.triu_indices_from(mask)] = True
            
            sns.heatmap(
                corr_matrix,
                mask=mask,
                annot=True,
                cmap='coolwarm',
                center=0,
                square=True,
                linewidths=0.5,
                cbar_kws={"shrink": 0.8}
            )
            
            plt.title("–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            plt.tight_layout()
            plt.savefig(plots_dir / "correlation_matrix.png", dpi=300, bbox_inches='tight')
            plt.show()
    
    def _plot_feature_target_relationships(self, plots_dir):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∑–∞–∏–º–æ—Å–≤—è–∑–µ–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π"""
        numerical_features = self.config['preprocessing']['features'].get('numerical_features', [])
        
        if not numerical_features:
            numerical_features = self.df.select_dtypes(include=[np.number]).columns.tolist()
            numerical_features = [col for col in numerical_features if col != self.target_column]
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥—Ä–∞—Ñ–∏–∫–æ–≤
        features_to_plot = numerical_features[:4]
        
        if len(features_to_plot) > 0:
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            axes = axes.ravel()
            
            for i, feature in enumerate(features_to_plot):
                if feature in self.df.columns:
                    # Scatter plot
                    sns.scatterplot(data=self.df, x=feature, y=self.target_column, alpha=0.6, ax=axes[i])
                    axes[i].set_title(f"{feature} vs {self.target_column}")
                    axes[i].set_xlabel(feature)
                    axes[i].set_ylabel(self.target_column)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –ª–∏–Ω–∏—é —Ç—Ä–µ–Ω–¥–∞
                    z = np.polyfit(self.df[feature], self.df[self.target_column], 1)
                    p = np.poly1d(z)
                    axes[i].plot(self.df[feature], p(self.df[feature]), "r--", alpha=0.8)
            
            # –°–∫—Ä—ã–≤–∞–µ–º –ª–∏—à–Ω–∏–µ –æ—Å–∏
            for i in range(len(features_to_plot), len(axes)):
                axes[i].set_visible(False)
            
            plt.tight_layout()
            plt.savefig(plots_dir / "feature_target_relationships.png", dpi=300, bbox_inches='tight')
            plt.show()
    
    def generate_insights(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö –≤—ã–≤–æ–¥–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ EDA"""
        print("\nÔøΩÔøΩ –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–õ–Æ–ß–ï–í–´–• –í–´–í–û–î–û–í")
        print("=" * 50)
        
        insights = []
        
        # –ê–Ω–∞–ª–∏–∑ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        target = self.df[self.target_column]
        target_mean = target.mean()
        target_median = target.median()
        target_std = target.std()
        
        if abs(target_mean - target_median) > target_std * 0.5:
            insights.append("–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –∏–º–µ–µ—Ç –∞—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ (—Å–∫–æ—à–µ–Ω–Ω–æ—Å—Ç—å), —á—Ç–æ –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏.")
        else:
            insights.append("–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –∏–º–µ–µ—Ç –±–ª–∏–∑–∫–æ–µ –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, —á—Ç–æ –±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω–æ –¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.")
        
        # –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
        numerical_df = self.df.select_dtypes(include=[np.number])
        if len(numerical_df.columns) > 1:
            corr_matrix = numerical_df.corr()
            target_correlations = corr_matrix[self.target_column].abs().sort_values(ascending=False)
            
            top_correlations = target_correlations[1:4]  # –ò—Å–∫–ª—é—á–∞–µ–º —Å–∞–º—É —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
            if len(top_correlations) > 0:
                top_features = top_correlations.index.tolist()
                insights.append(f"–ù–∞–∏–±–æ–ª–µ–µ —Å–∏–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∏–º–µ—é—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏: {', '.join(top_features)}. –≠—Ç–æ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –∏—Ö –≤–∞–∂–Ω–æ—Å—Ç—å –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è.")
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        categorical_features = self.config['preprocessing']['features'].get('categorical_numeric_features', [])
        if categorical_features:
            insights.append(f"–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ({', '.join(categorical_features)}) —Ç—Ä–µ–±—É—é—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ) –ø–µ—Ä–µ–¥ –ø–æ–¥–∞—á–µ–π –≤ –º–æ–¥–µ–ª—å.")
        
        # –ê–Ω–∞–ª–∏–∑ –≤—ã–±—Ä–æ—Å–æ–≤
        Q1 = target.quantile(0.25)
        Q3 = target.quantile(0.75)
        IQR = Q3 - Q1
        outliers_count = len(target[(target < Q1 - 1.5 * IQR) | (target > Q3 + 1.5 * IQR)])
        outliers_percent = (outliers_count / len(target)) * 100
        
        if outliers_percent > 5:
            insights.append(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–±—Ä–æ—Å–æ–≤ –≤ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π ({outliers_percent:.1f}%), —á—Ç–æ –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–æ–±–∞—Å—Ç–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤.")
        else:
            insights.append("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–±—Ä–æ—Å–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö –º–∏–Ω–∏–º–∞–ª—å–Ω–æ, —á—Ç–æ –±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω–æ –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.")
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
        if self.df.shape[1] > 20:
            insights.append("–í—ã—Å–æ–∫–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤ –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è.")
        else:
            insights.append("–£–º–µ—Ä–µ–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏.")
        
        # –í—ã–≤–æ–¥–∏–º –≤—ã–≤–æ–¥—ã
        print("ÔøΩÔøΩ –ö–õ–Æ–ß–ï–í–´–ï –í–´–í–û–î–´ –ü–û–°–õ–ï EDA:")
        print("=" * 50)
        for i, insight in enumerate(insights, 1):
            print(f"{i}. {insight}")
        
        return insights
    
    def save_eda_report(self, insights):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ EDA"""
        print("\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –û–¢–ß–ï–¢–ê EDA")
        print("=" * 50)
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –æ—Ç—á–µ—Ç–æ–≤
        reports_dir = Path("reports")
        reports_dir.mkdir(exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º markdown –æ—Ç—á–µ—Ç
        report_path = reports_dir / "eda_report.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# –û—Ç—á–µ—Ç –ø–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–º—É –∞–Ω–∞–ª–∏–∑—É –¥–∞–Ω–Ω—ã—Ö (EDA)\n\n")
            f.write("## –ü—Ä–æ–µ–∫—Ç: –£–ª—É—á—à–µ–Ω–∏–µ baseline-–º–æ–¥–µ–ª–∏ –¥–ª—è –Ø–Ω–¥–µ–∫—Å –ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏\n\n")
            f.write("## –î–∞—Ç–∞—Å–µ—Ç\n\n")
            f.write(f"- **–§–∞–π–ª:** {self.data_path}\n")
            f.write(f"- **–†–∞–∑–º–µ—Ä:** {self.df.shape[0]:,} —Å—Ç—Ä–æ–∫ √ó {self.df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤\n")
            f.write(f"- **–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è:** {self.target_column}\n\n")
            
            f.write("## –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã\n\n")
            for i, insight in enumerate(insights, 1):
                f.write(f"{i}. {insight}\n\n")
            
            f.write("## –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Å–≤–æ–¥–∫–∞\n\n")
            f.write("### –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n\n")
            numerical_features = self.config['preprocessing']['features'].get('numerical_features', [])
            if not numerical_features:
                numerical_features = self.df.select_dtypes(include=[np.number]).columns.tolist()
                numerical_features = [col for col in numerical_features if col != self.target_column]
            
            for feature in numerical_features:
                if feature in self.df.columns:
                    f.write(f"- **{feature}:**\n")
                    f.write(f"  - –°—Ä–µ–¥–Ω–µ–µ: {self.df[feature].mean():.2f}\n")
                    f.write(f"  - –ú–µ–¥–∏–∞–Ω–∞: {self.df[feature].median():.2f}\n")
                    f.write(f"  - –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {self.df[feature].std():.2f}\n\n")
            
            f.write("### –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n\n")
            categorical_features = self.config['preprocessing']['features'].get('categorical_numeric_features', [])
            for feature in categorical_features:
                if feature in self.df.columns:
                    f.write(f"- **{feature}:** {self.df[feature].nunique()} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n\n")
        
        print(f"‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
        
        return report_path
    
    
    def run_complete_eda(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ EDA –∞–Ω–∞–ª–∏–∑–∞"""
        print("ÔøΩÔøΩ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û EDA –ê–ù–ê–õ–ò–ó–ê")
        print("=" * 80)
        
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.load_data()
        
        # 2. –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
        self.basic_data_analysis()
        
        # 3. –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        self.numerical_features_analysis()
        self.categorical_features_analysis()
        self.boolean_features_analysis()
        
        # 4. –ê–Ω–∞–ª–∏–∑ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        self.target_analysis()
        
        # 5. –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
        self.create_visualizations()
        
        # 6. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—ã–≤–æ–¥–æ–≤
        insights = self.generate_insights()
        
        # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        report_path = self.save_eda_report(insights)
        
        
        print("\nüéâ EDA –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
        print("=" * 80)
        print(f"ÔøΩÔøΩ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {self.df.shape[0]:,} —Å—Ç—Ä–æ–∫ √ó {self.df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")
        print(f"üìÅ –ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫—É: plots/")
        print(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
        print(f"ÔøΩÔøΩ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(insights)} –∫–ª—é—á–µ–≤—ã—Ö –≤—ã–≤–æ–¥–æ–≤")
        
        return insights


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º
    data_path = "data/initial_data_set.csv"
    
    # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    analyzer = EDAAnalyzer(data_path)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    insights = analyzer.run_complete_eda()
    
    return insights


if __name__ == "__main__":
    main()