#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ð­Ñ‚Ð°Ð¿ 3: Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
ÐŸÑ€Ð¾ÐµÐºÑ‚: Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ðµ baseline-Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ Ð¯Ð½Ð´ÐµÐºÑ ÐÐµÐ´Ð²Ð¸Ð¶Ð¸Ð¼Ð¾ÑÑ‚Ð¸

Ð¢Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°:
1. Ð—Ð°Ð¹Ð¼Ð¸Ñ‚ÐµÑÑŒ Ð¿Ñ€ÐµÐ´Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¾Ð¹ Ð´Ð°Ð½Ð½Ñ‹Ñ…. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ðµ Ð¼ÐµÑ‚Ð¾Ð´Ñ‹ Ð¸Ð· sklearn.preprocessing
2. Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ sklearn.preprocessing. ÐŸÑ€Ð¸Ð¼ÐµÐ½Ð¸Ñ‚Ðµ ÐºÐ°Ðº Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ Ð´Ð²Ð° Ð¼ÐµÑ‚Ð¾Ð´Ð°:
   - PolynomialFeatures â€” Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð¿Ð¾Ð»Ð¸Ð½Ð¾Ð¼Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²
   - KBinsDiscretizer â€” Ð´Ð»Ñ Ð´Ð¸ÑÐºÑ€ÐµÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ñ… Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²
3. Ð¡Ð¾Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð²ÑÐµ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð² Ð¾Ð±ÑŠÐµÐºÑ‚ ColumnTransformer
4. Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ sklearn-Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½. Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð²Ð°Ñˆ ColumnTransformer Ð² Ð¾Ð±ÑŠÐµÐºÑ‚ Pipeline
5. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸ÑŽ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ¸ autofeat
6. ÐžÐ±ÑƒÑ‡Ð¸Ñ‚Ðµ Ð½Ð¾Ð²ÑƒÑŽ Ð²ÐµÑ€ÑÐ¸ÑŽ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ð° Ð¾Ð±Ð¾Ð³Ð°Ñ‰Ñ‘Ð½Ð½Ð¾Ð¼ Ð½Ð°Ð±Ð¾Ñ€Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²
7. ÐžÑ†ÐµÐ½Ð¸Ñ‚Ðµ ÐµÑ‘ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¸ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ
8. Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð·Ð°Ð»Ð¾Ð³Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð² MLflow
9. Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚Ðµ Ð½Ð¾Ð²ÑƒÑŽ Ð²ÐµÑ€ÑÐ¸ÑŽ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð² MLflow Model Registry
"""

import os
import warnings
import time
import yaml
import json
from pathlib import Path
from datetime import datetime

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder, KBinsDiscretizer, PolynomialFeatures
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð´Ð»Ñ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ñ€ÑƒÑÑÐºÐ¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°
plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial Unicode MS', 'SimHei']
warnings.filterwarnings("ignore")

class FeatureGenerator:
    """ÐšÐ»Ð°ÑÑ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸"""
    
    def __init__(self, data_path, config_path="../config.yaml"):
        """
        Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ð° Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²
        
        Args:
            data_path (str): ÐŸÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ…
            config_path (str): ÐŸÑƒÑ‚ÑŒ Ðº ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¾Ð½Ð½Ð¾Ð¼Ñƒ Ñ„Ð°Ð¹Ð»Ñƒ
        """
        self.data_path = data_path
        self.config_path = config_path
        self.df = None
        self.config = None
        self.target_column = None
        self.drop_columns = None
        self.numerical_features = None
        self.categorical_features = None
        self.boolean_features = None
        
        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ
        self._load_config()
        
        # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
        self._setup_display()
        
        # Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
        self.results = {}
        
    def _load_config(self):
        """Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð· YAML Ñ„Ð°Ð¹Ð»Ð°"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f)
            
            self.target_column = self.config['preprocessing']['features']['target_column']
            self.drop_columns = self.config['preprocessing']['features']['drop_columns']
            self.numerical_features = self.config['preprocessing']['features']['numerical_features']
            self.categorical_features = self.config['preprocessing']['features']['categorical_numeric_features']
            self.boolean_features = self.config['preprocessing']['features']['boolean_features']
            
            print("âœ… ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð° ÑƒÑÐ¿ÐµÑˆÐ½Ð¾")
            
        except Exception as e:
            print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸: {e}")
            # Ð—Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ
            self.target_column = 'price'
            self.drop_columns = ['id', 'building_id']
            self.numerical_features = ['total_area', 'rooms', 'floor', 'build_year']
            self.categorical_features = ['building_type']
            self.boolean_features = ['is_apartment', 'studio', 'has_elevator']
    
    def _setup_display(self):
        """ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ"""
        pd.options.display.max_columns = 100
        pd.options.display.max_rows = 64
        sns.set_theme(style="ticks", palette="pastel")
        plt.style.use('seaborn-v0_8')
    
    def load_data(self):
        """Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ñ Ð¿Ñ€ÐµÐ´Ð²Ð°Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¾Ð¹"""
        print("ðŸ“Š Ð—ÐÐ“Ð Ð£Ð—ÐšÐ Ð”ÐÐÐÐ«Ð¥...")
        print("=" * 50)
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ„Ð°Ð¹Ð»Ð°
        if not os.path.exists(self.data_path):
            raise FileNotFoundError(f"Ð¤Ð°Ð¹Ð» Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½: {self.data_path}")
        
        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸ÐµÐ¹ Ñ‚Ð¸Ð¿Ð¾Ð²
        try:
            self.df = pd.read_csv(self.data_path, dtype={
                "rooms": "category",
                "building_type": "category",
                "floor": "int16",
                "floors_total": "int16",
                "flats_count": "int32",
                "build_year": "int16",
                "is_apartment": "bool",
                "studio": "bool",
                "has_elevator": "bool"
            })
            
            print(f"âœ… Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾")
            print(f"   Ð Ð°Ð·Ð¼ÐµÑ€: {self.df.shape[0]:,} ÑÑ‚Ñ€Ð¾Ðº Ã— {self.df.shape[1]} ÑÑ‚Ð¾Ð»Ð±Ñ†Ð¾Ð²")
            print(f"   Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð°Ð¼ÑÑ‚Ð¸: {self.df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
            
        except Exception as e:
            print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ Ð´Ð°Ð½Ð½Ñ‹Ñ…: {e}")
            raise
        
        # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð½ÐµÐ½ÑƒÐ¶Ð½Ñ‹Ðµ ÑÑ‚Ð¾Ð»Ð±Ñ†Ñ‹
        columns_to_drop = list(set(self.df.columns) & set(self.drop_columns))
        if columns_to_drop:
            self.df.drop(columns=columns_to_drop, axis=1, inplace=True)
            print(f"   Ð£Ð´Ð°Ð»ÐµÐ½Ñ‹ ÑÑ‚Ð¾Ð»Ð±Ñ†Ñ‹: {columns_to_drop}")
            print(f"   ÐÐ¾Ð²Ñ‹Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ€: {self.df.shape[0]:,} ÑÑ‚Ñ€Ð¾Ðº Ã— {self.df.shape[1]} ÑÑ‚Ð¾Ð»Ð±Ñ†Ð¾Ð²")
        
        return self.df
    
    def manual_feature_engineering(self):
        """Ð ÑƒÑ‡Ð½Ð°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð´Ð¾Ð¼ÐµÐ½Ð½Ð¾Ð¹ ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð¸Ð·Ñ‹"""
        print("\nðŸ”§ Ð Ð£Ð§ÐÐÐ¯ Ð“Ð•ÐÐ•Ð ÐÐ¦Ð˜Ð¯ ÐŸÐ Ð˜Ð—ÐÐÐšÐžÐ’")
        print("=" * 50)
        
        start_time = time.time()
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÐºÐ¾Ð¿Ð¸ÑŽ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ feature engineering
        df_features = self.df.copy()
        
        print("ðŸ“Š Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð½Ð¾Ð²Ñ‹Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸...")
        
        # 1. ÐŸÐ»Ð¾Ñ‰Ð°Ð´ÑŒ Ð½Ð° ÐºÐ¾Ð¼Ð½Ð°Ñ‚Ñƒ
        df_features['area_per_room'] = df_features['total_area'] / df_features['rooms'].astype(float)
        print("   âœ… area_per_room - Ð¿Ð»Ð¾Ñ‰Ð°Ð´ÑŒ Ð½Ð° ÐºÐ¾Ð¼Ð½Ð°Ñ‚Ñƒ")
        
        # 2. ÐšÐ²Ð°Ð´Ñ€Ð°Ñ‚ Ð¾Ð±Ñ‰ÐµÐ¹ Ð¿Ð»Ð¾Ñ‰Ð°Ð´Ð¸
        df_features['total_area_sq'] = df_features['total_area'] ** 2
        print("   âœ… total_area_sq - ÐºÐ²Ð°Ð´Ñ€Ð°Ñ‚ Ð¾Ð±Ñ‰ÐµÐ¹ Ð¿Ð»Ð¾Ñ‰Ð°Ð´Ð¸")
        
        # 3. Ð¡Ð¾Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ðµ Ð¶Ð¸Ð»Ð¾Ð¹ Ð¸ Ð¾Ð±Ñ‰ÐµÐ¹ Ð¿Ð»Ð¾Ñ‰Ð°Ð´Ð¸
        df_features['living_to_total_ratio'] = df_features['living_area'] / df_features['total_area']
        print("   âœ… living_to_total_ratio - ÑÐ¾Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ðµ Ð¶Ð¸Ð»Ð¾Ð¹ Ð¸ Ð¾Ð±Ñ‰ÐµÐ¹ Ð¿Ð»Ð¾Ñ‰Ð°Ð´Ð¸")
        
        # 4. Ð¡Ð¾Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ðµ ÐºÑƒÑ…Ð¾Ð½Ð½Ð¾Ð¹ Ð¸ Ð¾Ð±Ñ‰ÐµÐ¹ Ð¿Ð»Ð¾Ñ‰Ð°Ð´Ð¸
        df_features['kitchen_to_total_ratio'] = df_features['kitchen_area'] / df_features['total_area']
        print("   âœ… kitchen_to_total_ratio - ÑÐ¾Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ðµ ÐºÑƒÑ…Ð¾Ð½Ð½Ð¾Ð¹ Ð¸ Ð¾Ð±Ñ‰ÐµÐ¹ Ð¿Ð»Ð¾Ñ‰Ð°Ð´Ð¸")
        
        # 5. Ð’Ð¾Ð·Ñ€Ð°ÑÑ‚ Ð·Ð´Ð°Ð½Ð¸Ñ
        current_year = datetime.now().year
        df_features['building_age'] = current_year - df_features['build_year']
        print("   âœ… building_age - Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚ Ð·Ð´Ð°Ð½Ð¸Ñ")
        
        # 6. ÐŸÐ»Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ Ð·Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ (ÐºÐ²Ð°Ñ€Ñ‚Ð¸Ñ€ Ð½Ð° ÑÑ‚Ð°Ð¶)
        df_features['flats_per_floor'] = df_features['flats_count'] / df_features['floors_total']
        print("   âœ… flats_per_floor - Ð¿Ð»Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ Ð·Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸")
        
        # 7. Ð Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð¾Ñ‚ Ñ†ÐµÐ½Ñ‚Ñ€Ð° (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ñ‹)
        if 'latitude' in df_features.columns and 'longitude' in df_features.columns:
            # Ð¦ÐµÐ½Ñ‚Ñ€ ÐœÐ¾ÑÐºÐ²Ñ‹ (Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð½Ñ‹Ðµ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ñ‹)
            moscow_center_lat, moscow_center_lon = 55.7558, 37.6176
            df_features['distance_from_center'] = np.sqrt(
                (df_features['latitude'] - moscow_center_lat) ** 2 + 
                (df_features['longitude'] - moscow_center_lon) ** 2
            ) * 111000  # ÐŸÑ€Ð¸Ð¼ÐµÑ€Ð½Ð¾ Ð² Ð¼ÐµÑ‚Ñ€Ð°Ñ…
            print("   âœ… distance_from_center - Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð¾Ñ‚ Ñ†ÐµÐ½Ñ‚Ñ€Ð° ÐœÐ¾ÑÐºÐ²Ñ‹")
        
        # 8. Ð›Ð¾Ð³Ð°Ñ€Ð¸Ñ„Ð¼ Ñ†ÐµÐ½Ñ‹ (Ð´Ð»Ñ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸)
        df_features['log_price'] = np.log1p(df_features[self.target_column])
        print("   âœ… log_price - Ð»Ð¾Ð³Ð°Ñ€Ð¸Ñ„Ð¼ Ñ†ÐµÐ½Ñ‹")
        
        # 9. Ð‘Ð¸Ð½Ð°Ñ€Ð½Ñ‹Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸ Ð´Ð»Ñ ÑÑ‚Ð°Ð¶Ð½Ð¾ÑÑ‚Ð¸
        df_features['is_high_floor'] = (df_features['floor'] > df_features['floors_total'] * 0.7).astype(int)
        df_features['is_low_floor'] = (df_features['floor'] <= 3).astype(int)
        print("   âœ… is_high_floor, is_low_floor - Ð±Ð¸Ð½Ð°Ñ€Ð½Ñ‹Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸ ÑÑ‚Ð°Ð¶Ð½Ð¾ÑÑ‚Ð¸")
        
        # 10. ÐšÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¸Ð·Ð½Ð°Ðº Ñ‚Ð¸Ð¿Ð° Ð·Ð´Ð°Ð½Ð¸Ñ Ð¸ Ð³Ð¾Ð´Ð° Ð¿Ð¾ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸
        df_features['building_type_age'] = df_features['building_type'].astype(str) + '_' + \
                                         df_features['build_year'].astype(str)
        print("   âœ… building_type_age - ÐºÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¸Ð·Ð½Ð°Ðº")
        
        # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð±ÐµÑÐºÐ¾Ð½ÐµÑ‡Ð½Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ
        df_features = df_features.replace([np.inf, -np.inf], np.nan)
        
        # Ð—Ð°Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ Ð¿Ñ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ð½Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð¿Ð¾ Ñ‚Ð¸Ð¿Ð°Ð¼ Ð´Ð°Ð½Ð½Ñ‹Ñ…
        for col in df_features.columns:
            if df_features[col].dtype.name == 'category':
                # Ð”Ð»Ñ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ mode (ÑÐ°Ð¼Ð¾Ðµ Ñ‡Ð°ÑÑ‚Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ)
                mode_value = df_features[col].mode().iloc[0] if not df_features[col].mode().empty else df_features[col].iloc[0]
                df_features[col] = df_features[col].fillna(mode_value)
            elif df_features[col].dtype.name == 'bool':
                # Ð”Ð»Ñ Ð±ÑƒÐ»ÐµÐ²Ñ‹Ñ… Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ False
                df_features[col] = df_features[col].fillna(False)
            else:
                # Ð”Ð»Ñ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ñ… Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ 0
                df_features[col] = df_features[col].fillna(0)
        
        elapsed_time = time.time() - start_time
        print(f"\nâœ… Ð ÑƒÑ‡Ð½Ð°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð° Ð·Ð° {elapsed_time:.2f} ÑÐµÐº")
        print(f"   ÐÐ¾Ð²Ñ‹Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ€: {df_features.shape[0]:,} ÑÑ‚Ñ€Ð¾Ðº Ã— {df_features.shape[1]} ÑÑ‚Ð¾Ð»Ð±Ñ†Ð¾Ð²")
        
        self.df_features = df_features
        return df_features
    
    def create_sklearn_preprocessor(self):
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ sklearn Ð¿Ñ€ÐµÐ¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ñ€Ð° Ñ ColumnTransformer"""
        print("\nðŸ”§ Ð¡ÐžÐ—Ð”ÐÐÐ˜Ð• SKLEARN ÐŸÐ Ð•ÐŸÐ ÐžÐ¦Ð•Ð¡Ð¡ÐžÐ Ð")
        print("=" * 50)
        
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸ (Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ Ð½Ð¾Ð²Ñ‹Ðµ)
        numerical_features = [col for col in self.df_features.columns 
                            if col not in [self.target_column] + self.categorical_features + self.boolean_features]
        
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸
        categorical_features = [col for col in self.categorical_features 
                              if col in self.df_features.columns]
        
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð±ÑƒÐ»ÐµÐ²Ñ‹ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸
        boolean_features = [col for col in self.boolean_features 
                          if col in self.df_features.columns]
        
        print(f"ðŸ“Š Ð§Ð¸ÑÐ»Ð¾Ð²Ñ‹Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸: {len(numerical_features)}")
        print(f"ðŸ“Š ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸: {len(categorical_features)}")
        print(f"ðŸ“Š Ð‘ÑƒÐ»ÐµÐ²Ñ‹ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸: {len(boolean_features)}")
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼ÐµÑ€Ñ‹ Ð´Ð»Ñ Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ñ‚Ð¸Ð¿Ð¾Ð² Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²
        transformers = []
        
        # 1. Ð§Ð¸ÑÐ»Ð¾Ð²Ñ‹Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸
        if numerical_features:
            numerical_transformer = Pipeline([
                ('scaler', StandardScaler()),
                ('polynomial', PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)),
                ('discretizer', KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile'))
            ])
            transformers.append(('numerical', numerical_transformer, numerical_features))
            print("   âœ… Ð§Ð¸ÑÐ»Ð¾Ð²Ð¾Ð¹ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼ÐµÑ€ ÑÐ¾Ð·Ð´Ð°Ð½")
        
        # 2. ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸
        if categorical_features:
            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ OrdinalEncoder Ð²Ð¼ÐµÑÑ‚Ð¾ LabelEncoder Ð´Ð»Ñ ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð¾ÑÑ‚Ð¸ Ñ Pipeline
            from sklearn.preprocessing import OrdinalEncoder
            categorical_transformer = Pipeline([
                ('ordinal_encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))
            ])
            transformers.append(('categorical', categorical_transformer, categorical_features))
            print("   âœ… ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼ÐµÑ€ ÑÐ¾Ð·Ð´Ð°Ð½")
        
        # 3. Ð‘ÑƒÐ»ÐµÐ²Ñ‹ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸ (Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ°Ðº ÐµÑÑ‚ÑŒ)
        if boolean_features:
            transformers.append(('boolean', 'passthrough', boolean_features))
            print("   âœ… Ð‘ÑƒÐ»ÐµÐ² Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼ÐµÑ€ ÑÐ¾Ð·Ð´Ð°Ð½")
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ColumnTransformer
        preprocessor = ColumnTransformer(
            transformers=transformers,
            remainder='drop',
            sparse_threshold=0.3
        )
        
        print(f"\nâœ… ColumnTransformer ÑÐ¾Ð·Ð´Ð°Ð½ Ñ {len(transformers)} Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼ÐµÑ€Ð°Ð¼Ð¸")
        
        self.preprocessor = preprocessor
        self.numerical_features = numerical_features
        self.categorical_features = categorical_features
        self.boolean_features = boolean_features
        
        return preprocessor
    
    def create_sklearn_pipeline(self):
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ sklearn Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½Ð°"""
        print("\nðŸ”§ Ð¡ÐžÐ—Ð”ÐÐÐ˜Ð• SKLEARN ÐŸÐÐ™ÐŸÐ›ÐÐ™ÐÐ")
        print("=" * 50)
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ XGBoost Ð¼Ð¾Ð´ÐµÐ»ÑŒ
        xgb_model = xgb.XGBRegressor(
            n_estimators=self.config['model']['params']['n_estimators'],
            max_depth=self.config['model']['params']['max_depth'],
            learning_rate=self.config['model']['params']['learning_rate'],
            subsample=self.config['model']['params']['subsample'],
            colsample_bytree=self.config['model']['params']['colsample_bytree'],
            random_state=self.config['train']['random_state'],
            eval_metric=self.config['model']['params']['eval_metric'],
            objective=self.config['model']['params']['objective'],
            tree_method=self.config['model']['params']['tree_method'],
            n_jobs=self.config['model']['params']['n_jobs']
        )
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½
        pipeline = Pipeline([
            ('preprocessor', self.preprocessor),
            ('regressor', xgb_model)
        ])
        
        print("âœ… Sklearn Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½ ÑÐ¾Ð·Ð´Ð°Ð½:")
        print("   1. Preprocessor (ColumnTransformer)")
        print("   2. XGBoost Regressor")
        
        self.pipeline = pipeline
        return pipeline
    
    def prepare_data_for_training(self):
        """ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ"""
        print("\nðŸ”§ ÐŸÐžÐ”Ð“ÐžÐ¢ÐžÐ’ÐšÐ Ð”ÐÐÐÐ«Ð¥ Ð”Ð›Ð¯ ÐžÐ‘Ð£Ð§Ð•ÐÐ˜Ð¯")
        print("=" * 50)
        
        # Ð Ð°Ð·Ð´ÐµÐ»ÑÐµÐ¼ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸ Ð¸ Ñ†ÐµÐ»ÐµÐ²ÑƒÑŽ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ
        X = self.df_features.drop(columns=[self.target_column])
        y = self.df_features[self.target_column]
        
        print(f"ðŸ“Š ÐŸÑ€Ð¸Ð·Ð½Ð°ÐºÐ¸: {X.shape[1]} ÑÑ‚Ð¾Ð»Ð±Ñ†Ð¾Ð²")
        print(f"ðŸ“Š Ð¦ÐµÐ»ÐµÐ²Ð°Ñ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ: {y.shape[0]} Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹")
        
        # Ð Ð°Ð·Ð´ÐµÐ»ÑÐµÐ¼ Ð½Ð° Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰ÑƒÑŽ Ð¸ Ñ‚ÐµÑÑ‚Ð¾Ð²ÑƒÑŽ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸
        X_train, X_test, y_train, y_test = train_test_split(
            X, y,
            test_size=self.config['train']['test_size'],
            random_state=self.config['train']['random_state'],
            shuffle=self.config['train']['shuffle']
        )
        
        print(f"ðŸ“Š ÐžÐ±ÑƒÑ‡Ð°ÑŽÑ‰Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°: {X_train.shape[0]:,} ÑÑ‚Ñ€Ð¾Ðº")
        print(f"ðŸ“Š Ð¢ÐµÑÑ‚Ð¾Ð²Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°: {X_test.shape[0]:,} ÑÑ‚Ñ€Ð¾Ðº")
        
        self.X_train = X_train
        self.X_test = X_test
        self.y_train = y_train
        self.y_test = y_test
        
        return X_train, X_test, y_train, y_test
    
    def train_pipeline_model(self):
        """ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ñ‡ÐµÑ€ÐµÐ· Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½"""
        print("\nðŸš€ ÐžÐ‘Ð£Ð§Ð•ÐÐ˜Ð• ÐœÐžÐ”Ð•Ð›Ð˜ Ð§Ð•Ð Ð•Ð— ÐŸÐÐ™ÐŸÐ›ÐÐ™Ð")
        print("=" * 50)
        
        start_time = time.time()
        
        # ÐžÐ±ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½
        print("ðŸ“Š ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½Ð°...")
        self.pipeline.fit(self.X_train, self.y_train)
        
        elapsed_time = time.time() - start_time
        print(f"âœ… ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾ Ð·Ð° {elapsed_time:.2f} ÑÐµÐº")
        
        # ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ
        y_train_pred = self.pipeline.predict(self.X_train)
        y_test_pred = self.pipeline.predict(self.X_test)
        
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ
        self.y_train_pred = y_train_pred
        self.y_test_pred = y_test_pred
        
        return y_train_pred, y_test_pred
    
    def evaluate_model(self):
        """ÐžÑ†ÐµÐ½ÐºÐ° ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ð¼Ð¾Ð´ÐµÐ»Ð¸"""
        print("\nðŸ“Š ÐžÐ¦Ð•ÐÐšÐ ÐšÐÐ§Ð•Ð¡Ð¢Ð’Ð ÐœÐžÐ”Ð•Ð›Ð˜")
        print("=" * 50)
        
        # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰ÐµÐ¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸
        train_rmse = np.sqrt(mean_squared_error(self.y_train, self.y_train_pred))
        train_mae = mean_absolute_error(self.y_train, self.y_train_pred)
        train_r2 = r2_score(self.y_train, self.y_train_pred)
        
        # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸
        test_rmse = np.sqrt(mean_squared_error(self.y_test, self.y_test_pred))
        test_mae = mean_absolute_error(self.y_test, self.y_test_pred)
        test_r2 = r2_score(self.y_test, self.y_test_pred)
        
        # MAPE
        train_mape = np.mean(np.abs((self.y_train - self.y_train_pred) / self.y_train)) * 100
        test_mape = np.mean(np.abs((self.y_test - self.y_test_pred) / self.y_test)) * 100
        
        print("ðŸ“Š ÐœÐ•Ð¢Ð Ð˜ÐšÐ˜ ÐšÐÐ§Ð•Ð¡Ð¢Ð’Ð:")
        print("=" * 30)
        print(f"ÐžÐ±ÑƒÑ‡Ð°ÑŽÑ‰Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°:")
        print(f"  RMSE: {train_rmse:,.0f}")
        print(f"  MAE:  {train_mae:,.0f}")
        print(f"  RÂ²:   {train_r2:.4f}")
        print(f"  MAPE: {train_mape:.2f}%")
        print()
        print(f"Ð¢ÐµÑÑ‚Ð¾Ð²Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°:")
        print(f"  RMSE: {test_rmse:,.0f}")
        print(f"  MAE:  {test_mae:,.0f}")
        print(f"  RÂ²:   {test_r2:.4f}")
        print(f"  MAPE: {test_mape:.2f}%")
        
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
        self.results = {
            'train': {
                'rmse': train_rmse,
                'mae': train_mae,
                'r2': train_r2,
                'mape': train_mape
            },
            'test': {
                'rmse': test_rmse,
                'mae': test_mae,
                'r2': test_r2,
                'mape': test_mape
            }
        }
        
        return self.results
    
    def cross_validation_analysis(self):
        """ÐÐ½Ð°Ð»Ð¸Ð· ÐºÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸"""
        print("\nðŸ”„ ÐÐÐÐ›Ð˜Ð— ÐšÐ ÐžÐ¡Ð¡-Ð’ÐÐ›Ð˜Ð”ÐÐ¦Ð˜Ð˜")
        print("=" * 50)
        
        # ÐšÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ
        cv_scores = cross_val_score(
            self.pipeline,
            self.X_train,
            self.y_train,
            cv=5,
            scoring='neg_root_mean_squared_error',
            n_jobs=-1
        )
        
        # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ Ð² Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ
        cv_rmse = -cv_scores
        cv_mean = cv_rmse.mean()
        cv_std = cv_rmse.std()
        
        print(f"ðŸ“Š ÐšÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ (5 Ñ„Ð¾Ð»Ð´Ð¾Ð²):")
        print(f"  Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹ RMSE: {cv_mean:,.0f} Â± {cv_std:,.0f}")
        print(f"  ÐžÑ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ñ„Ð¾Ð»Ð´Ñ‹:")
        for i, score in enumerate(cv_rmse, 1):
            print(f"    Ð¤Ð¾Ð»Ð´ {i}: {score:,.0f}")
        
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ CV
        self.results['cross_validation'] = {
            'mean_rmse': cv_mean,
            'std_rmse': cv_std,
            'fold_scores': cv_rmse.tolist()
        }
        
        return cv_mean, cv_std
    
    def feature_importance_analysis(self):
        """ÐÐ½Ð°Ð»Ð¸Ð· Ð²Ð°Ð¶Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²"""
        print("\nðŸ” ÐÐÐÐ›Ð˜Ð— Ð’ÐÐ–ÐÐžÐ¡Ð¢Ð˜ ÐŸÐ Ð˜Ð—ÐÐÐšÐžÐ’")
        print("=" * 50)
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð¿Ð¾ÑÐ»Ðµ Ð¿Ñ€ÐµÐ¿Ñ€Ð¾Ñ†ÐµÑÑÐ¸Ð½Ð³Ð°
        feature_names = []
        
        # Ð§Ð¸ÑÐ»Ð¾Ð²Ñ‹Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸
        if hasattr(self.preprocessor, 'named_transformers_'):
            if 'numerical' in self.preprocessor.named_transformers_:
                numerical_transformer = self.preprocessor.named_transformers_['numerical']
                if hasattr(numerical_transformer, 'named_steps_'):
                    if 'polynomial' in numerical_transformer.named_steps_:
                        poly_transformer = numerical_transformer.named_steps_['polynomial']
                        feature_names.extend(poly_transformer.get_feature_names_out(self.numerical_features))
                    else:
                        feature_names.extend(self.numerical_features)
                else:
                    feature_names.extend(self.numerical_features)
            else:
                feature_names.extend(self.numerical_features)
        
        # ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸
        feature_names.extend(self.categorical_features)
        
        # Ð‘ÑƒÐ»ÐµÐ²Ñ‹ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸
        feature_names.extend(self.boolean_features)
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð²Ð°Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð¸Ð· XGBoost
        if hasattr(self.pipeline, 'named_steps_'):
            xgb_model = self.pipeline.named_steps_['regressor']
            if hasattr(xgb_model, 'feature_importances_'):
                importances = xgb_model.feature_importances_
                
                # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ DataFrame Ñ Ð²Ð°Ð¶Ð½Ð¾ÑÑ‚ÑŒÑŽ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²
                feature_importance_df = pd.DataFrame({
                    'feature': feature_names[:len(importances)],
                    'importance': importances
                }).sort_values('importance', ascending=False)
                
                print("ðŸ” Ð¢Ð¾Ð¿-15 Ð²Ð°Ð¶Ð½Ñ‹Ñ… Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²:")
                print(feature_importance_df.head(15))
                
                # Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð²Ð°Ð¶Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²
                self._plot_feature_importance(feature_importance_df)
                
                # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
                self.results['feature_importance'] = feature_importance_df.to_dict('records')
                
                return feature_importance_df
        
        print("âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð²Ð°Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²")
        return None
    
    def _plot_feature_importance(self, feature_importance_df):
        """Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð²Ð°Ð¶Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²"""
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¿Ð°Ð¿ÐºÑƒ Ð´Ð»Ñ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¾Ð²
        plots_dir = Path("plots")
        plots_dir.mkdir(exist_ok=True)
        
        # Ð¢Ð¾Ð¿-20 Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²
        top_features = feature_importance_df.head(20)
        
        plt.figure(figsize=(12, 8))
        sns.barplot(data=top_features, x='importance', y='feature')
        plt.title("Ð’Ð°Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² (Ñ‚Ð¾Ð¿-20)")
        plt.xlabel("Ð’Ð°Ð¶Ð½Ð¾ÑÑ‚ÑŒ")
        plt.ylabel("ÐŸÑ€Ð¸Ð·Ð½Ð°Ðº")
        plt.tight_layout()
        plt.savefig(plots_dir / "feature_importance.png", dpi=300, bbox_inches='tight')
        plt.show()
    
    def create_visualizations(self):
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²"""
        print("\nðŸŽ¨ Ð¡ÐžÐ—Ð”ÐÐÐ˜Ð• Ð’Ð˜Ð—Ð£ÐÐ›Ð˜Ð—ÐÐ¦Ð˜Ð™")
        print("=" * 50)
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¿Ð°Ð¿ÐºÑƒ Ð´Ð»Ñ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¾Ð²
        plots_dir = Path("plots")
        plots_dir.mkdir(exist_ok=True)
        
        # 1. Actual vs Predicted
        self._plot_actual_vs_predicted(plots_dir)
        
        # 2. Residuals plot
        self._plot_residuals(plots_dir)
        
        # 3. Distribution of predictions
        self._plot_prediction_distribution(plots_dir)
        
        print(f"âœ… Ð“Ñ€Ð°Ñ„Ð¸ÐºÐ¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð² Ð¿Ð°Ð¿ÐºÑƒ: {plots_dir}")
    
    def _plot_actual_vs_predicted(self, plots_dir):
        """Ð“Ñ€Ð°Ñ„Ð¸Ðº Ñ„Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… vs Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ñ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹"""
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        
        # ÐžÐ±ÑƒÑ‡Ð°ÑŽÑ‰Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°
        axes[0].scatter(self.y_train, self.y_train_pred, alpha=0.6)
        axes[0].plot([self.y_train.min(), self.y_train.max()], 
                     [self.y_train.min(), self.y_train.max()], 'r--', lw=2)
        axes[0].set_xlabel('Ð¤Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ')
        axes[0].set_ylabel('ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ')
        axes[0].set_title('ÐžÐ±ÑƒÑ‡Ð°ÑŽÑ‰Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°')
        axes[0].grid(True, alpha=0.3)
        
        # Ð¢ÐµÑÑ‚Ð¾Ð²Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°
        axes[1].scatter(self.y_test, self.y_test_pred, alpha=0.6)
        axes[1].plot([self.y_test.min(), self.y_test.max()], 
                     [self.y_test.min(), self.y_test.max()], 'r--', lw=2)
        axes[1].set_xlabel('Ð¤Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ')
        axes[1].set_ylabel('ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ')
        axes[1].set_title('Ð¢ÐµÑÑ‚Ð¾Ð²Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°')
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(plots_dir / "actual_vs_predicted.png", dpi=300, bbox_inches='tight')
        plt.show()
    
    def _plot_residuals(self, plots_dir):
        """Ð“Ñ€Ð°Ñ„Ð¸Ðº Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ¾Ð²"""
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        
        # ÐžÑÑ‚Ð°Ñ‚ÐºÐ¸ Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰ÐµÐ¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸
        train_residuals = self.y_train - self.y_train_pred
        axes[0].scatter(self.y_train_pred, train_residuals, alpha=0.6)
        axes[0].axhline(y=0, color='r', linestyle='--')
        axes[0].set_xlabel('ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ')
        axes[0].set_ylabel('ÐžÑÑ‚Ð°Ñ‚ÐºÐ¸')
        axes[0].set_title('ÐžÑÑ‚Ð°Ñ‚ÐºÐ¸ (Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°)')
        axes[0].grid(True, alpha=0.3)
        
        # ÐžÑÑ‚Ð°Ñ‚ÐºÐ¸ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸
        test_residuals = self.y_test - self.y_test_pred
        axes[1].scatter(self.y_test_pred, test_residuals, alpha=0.6)
        axes[1].axhline(y=0, color='r', linestyle='--')
        axes[1].set_xlabel('ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ')
        axes[1].set_ylabel('ÐžÑÑ‚Ð°Ñ‚ÐºÐ¸')
        axes[1].set_title('ÐžÑÑ‚Ð°Ñ‚ÐºÐ¸ (Ñ‚ÐµÑÑ‚Ð¾Ð²Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°)')
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(plots_dir / "residuals.png", dpi=300, bbox_inches='tight')
        plt.show()
    
    def _plot_prediction_distribution(self, plots_dir):
        """Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹"""
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        
        # Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹ Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰ÐµÐ¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸
        axes[0].hist(self.y_train_pred, bins=50, alpha=0.7, label='ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ')
        axes[0].hist(self.y_train, bins=50, alpha=0.7, label='Ð¤Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ')
        axes[0].set_xlabel('Ð¦ÐµÐ½Ð°')
        axes[0].set_ylabel('Ð§Ð°ÑÑ‚Ð¾Ñ‚Ð°')
        axes[0].set_title('Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ (Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°)')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        
        # Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸
        axes[1].hist(self.y_test_pred, bins=50, alpha=0.7, label='ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ')
        axes[1].hist(self.y_test, bins=50, alpha=0.7, label='Ð¤Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ')
        axes[1].set_xlabel('Ð¦ÐµÐ½Ð°')
        axes[1].set_ylabel('Ð§Ð°ÑÑ‚Ð¾Ñ‚Ð°')
        axes[1].set_title('Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ (Ñ‚ÐµÑÑ‚Ð¾Ð²Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°)')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(plots_dir / "prediction_distribution.png", dpi=300, bbox_inches='tight')
        plt.show()
    
    def save_results(self):
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²"""
        print("\nðŸ’¾ Ð¡ÐžÐ¥Ð ÐÐÐ•ÐÐ˜Ð• Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢ÐžÐ’")
        print("=" * 50)
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¿Ð°Ð¿ÐºÑƒ Ð´Ð»Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
        results_dir = Path("results")
        results_dir.mkdir(exist_ok=True)
        
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
        model_path = results_dir / "feature_generation_model.pkl"
        import pickle
        with open(model_path, 'wb') as f:
            pickle.dump(self.pipeline, f)
        print(f"âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð°: {model_path}")
        
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð² JSON
        results_path = results_dir / "feature_generation_results.json"
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False, default=str)
        print(f"âœ… Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹: {results_path}")
        
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¾Ñ‚Ñ‡ÐµÑ‚
        report_path = results_dir / "feature_generation_report.md"
        self._save_report(report_path)
        print(f"âœ… ÐžÑ‚Ñ‡ÐµÑ‚ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½: {report_path}")
        
        return model_path, results_path, report_path
    
    def _save_report(self, report_path):
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð° Ð² markdown"""
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# ÐžÑ‚Ñ‡ÐµÑ‚ Ð¿Ð¾ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸ÑŽ Ð¼Ð¾Ð´ÐµÐ»Ð¸\n\n")
            f.write("## ÐŸÑ€Ð¾ÐµÐºÑ‚: Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ðµ baseline-Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ Ð¯Ð½Ð´ÐµÐºÑ ÐÐµÐ´Ð²Ð¸Ð¶Ð¸Ð¼Ð¾ÑÑ‚Ð¸\n\n")
            f.write("## Ð­Ñ‚Ð°Ð¿ 3: Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸\n\n")
            
            f.write("## Ð¡Ð¾Ð·Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸\n\n")
            f.write("### Ð ÑƒÑ‡Ð½Ð°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ:\n")
            f.write("- area_per_room - Ð¿Ð»Ð¾Ñ‰Ð°Ð´ÑŒ Ð½Ð° ÐºÐ¾Ð¼Ð½Ð°Ñ‚Ñƒ\n")
            f.write("- total_area_sq - ÐºÐ²Ð°Ð´Ñ€Ð°Ñ‚ Ð¾Ð±Ñ‰ÐµÐ¹ Ð¿Ð»Ð¾Ñ‰Ð°Ð´Ð¸\n")
            f.write("- living_to_total_ratio - ÑÐ¾Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ðµ Ð¶Ð¸Ð»Ð¾Ð¹ Ð¸ Ð¾Ð±Ñ‰ÐµÐ¹ Ð¿Ð»Ð¾Ñ‰Ð°Ð´Ð¸\n")
            f.write("- kitchen_to_total_ratio - ÑÐ¾Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ðµ ÐºÑƒÑ…Ð¾Ð½Ð½Ð¾Ð¹ Ð¸ Ð¾Ð±Ñ‰ÐµÐ¹ Ð¿Ð»Ð¾Ñ‰Ð°Ð´Ð¸\n")
            f.write("- building_age - Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚ Ð·Ð´Ð°Ð½Ð¸Ñ\n")
            f.write("- flats_per_floor - Ð¿Ð»Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ Ð·Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸\n")
            f.write("- distance_from_center - Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð¾Ñ‚ Ñ†ÐµÐ½Ñ‚Ñ€Ð°\n")
            f.write("- log_price - Ð»Ð¾Ð³Ð°Ñ€Ð¸Ñ„Ð¼ Ñ†ÐµÐ½Ñ‹\n")
            f.write("- is_high_floor, is_low_floor - Ð±Ð¸Ð½Ð°Ñ€Ð½Ñ‹Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸ ÑÑ‚Ð°Ð¶Ð½Ð¾ÑÑ‚Ð¸\n")
            f.write("- building_type_age - ÐºÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¸Ð·Ð½Ð°Ðº\n\n")
            
            f.write("### ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ (sklearn):\n")
            f.write("- PolynomialFeatures (ÑÑ‚ÐµÐ¿ÐµÐ½ÑŒ 2, Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ)\n")
            f.write("- KBinsDiscretizer (5 Ð±Ð¸Ð½Ð¾Ð², ÐºÐ²Ð°Ð½Ñ‚Ð¸Ð»ÑŒÐ½Ð°Ñ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ñ)\n")
            f.write("- StandardScaler Ð´Ð»Ñ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ñ… Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²\n")
            f.write("- LabelEncoder Ð´Ð»Ñ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²\n\n")
            
            f.write("## Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ\n\n")
            f.write("### ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°:\n")
            f.write(f"- **ÐžÐ±ÑƒÑ‡Ð°ÑŽÑ‰Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°:**\n")
            f.write(f"  - RMSE: {self.results['train']['rmse']:,.0f}\n")
            f.write(f"  - MAE: {self.results['train']['mae']:,.0f}\n")
            f.write(f"  - RÂ²: {self.results['train']['r2']:.4f}\n")
            f.write(f"  - MAPE: {self.results['train']['mape']:.2f}%\n\n")
            
            f.write(f"- **Ð¢ÐµÑÑ‚Ð¾Ð²Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°:**\n")
            f.write(f"  - RMSE: {self.results['test']['rmse']:,.0f}\n")
            f.write(f"  - MAE: {self.results['test']['mae']:,.0f}\n")
            f.write(f"  - RÂ²: {self.results['test']['r2']:.4f}\n")
            f.write(f"  - MAPE: {self.results['test']['mape']:.2f}%\n\n")
            
            if 'cross_validation' in self.results:
                f.write("### ÐšÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ:\n")
                f.write(f"- Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹ RMSE: {self.results['cross_validation']['mean_rmse']:,.0f}\n")
                f.write(f"- Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð¾Ðµ Ð¾Ñ‚ÐºÐ»Ð¾Ð½ÐµÐ½Ð¸Ðµ: {self.results['cross_validation']['std_rmse']:,.0f}\n\n")
            
            f.write("## ÐÑ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° Ñ€ÐµÑˆÐµÐ½Ð¸Ñ\n\n")
            f.write("1. **Ð ÑƒÑ‡Ð½Ð°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²** Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð´Ð¾Ð¼ÐµÐ½Ð½Ð¾Ð¹ ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð¸Ð·Ñ‹\n")
            f.write("2. **Sklearn Pipeline** Ñ ColumnTransformer\n")
            f.write("3. **ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ** Ð¿Ð¾Ð»Ð¸Ð½Ð¾Ð¼Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²\n")
            f.write("4. **Ð”Ð¸ÑÐºÑ€ÐµÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ** Ñ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ñ… Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²\n")
            f.write("5. **XGBoost** ÐºÐ°Ðº Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ\n")
            f.write("6. **ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ð°Ñ Ð¾Ñ†ÐµÐ½ÐºÐ°** ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ð¼Ð¾Ð´ÐµÐ»Ð¸\n")
    
    def run_complete_feature_generation(self):
        """Ð—Ð°Ð¿ÑƒÑÐº Ð¿Ð¾Ð»Ð½Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²"""
        print("ðŸš€ Ð—ÐÐŸÐ£Ð¡Ðš ÐŸÐžÐ›ÐÐžÐ“Ðž ÐŸÐ ÐžÐ¦Ð•Ð¡Ð¡Ð Ð“Ð•ÐÐ•Ð ÐÐ¦Ð˜Ð˜ ÐŸÐ Ð˜Ð—ÐÐÐšÐžÐ’")
        print("=" * 80)
        
        start_time = time.time()
        
        # 1. Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…
        self.load_data()
        
        # 2. Ð ÑƒÑ‡Ð½Ð°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²
        self.manual_feature_engineering()
        
        # 3. Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ sklearn Ð¿Ñ€ÐµÐ¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ñ€Ð°
        self.create_sklearn_preprocessor()
        
        # 4. Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ sklearn Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½Ð°
        self.create_sklearn_pipeline()
        
        # 5. ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
        self.prepare_data_for_training()
        
        # 6. ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        self.train_pipeline_model()
        
        # 7. ÐžÑ†ÐµÐ½ÐºÐ° ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°
        self.evaluate_model()
        
        # 8. ÐšÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ
        self.cross_validation_analysis()
        
        # 9. ÐÐ½Ð°Ð»Ð¸Ð· Ð²Ð°Ð¶Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²
        self.feature_importance_analysis()
        
        # 10. Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¹
        self.create_visualizations()
        
        # 11. Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
        model_path, results_path, report_path = self.save_results()
        
        elapsed_time = time.time() - start_time
        
        print("\nðŸŽ‰ Ð“Ð•ÐÐ•Ð ÐÐ¦Ð˜Ð¯ ÐŸÐ Ð˜Ð—ÐÐÐšÐžÐ’ Ð—ÐÐ’Ð•Ð Ð¨Ð•ÐÐ Ð£Ð¡ÐŸÐ•Ð¨ÐÐž!")
        print("=" * 80)
        print(f"â±ï¸ ÐžÐ±Ñ‰ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ: {elapsed_time:.2f} ÑÐµÐº")
        print(f"ðŸ“Š Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¾ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²: {self.df_features.shape[1] - self.df.shape[1] + 1}")
        print(f"ðŸ“ ÐœÐ¾Ð´ÐµÐ»ÑŒ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð°: {model_path}")
        print(f"ðŸ“„ Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹: {results_path}")
        print(f"ðŸ“‹ ÐžÑ‚Ñ‡ÐµÑ‚ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½: {report_path}")
        
        return self.results


def main():
    """ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ"""
    # ÐŸÑƒÑ‚ÑŒ Ðº Ð´Ð°Ð½Ð½Ñ‹Ð¼
    data_path = "data/initial_data_set.csv"
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð³ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²
    feature_generator = FeatureGenerator(data_path)
    
    # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ
    results = feature_generator.run_complete_feature_generation()
    
    return results


if __name__ == "__main__":
    main()
