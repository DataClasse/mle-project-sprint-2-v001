# Проект: Улучшение baseline-модели прогнозирования стоимости недвижимости

## Описание проекта

Данный проект направлен на улучшение baseline-модели для прогнозирования стоимости недвижимости в рамках платформы Яндекс Недвижимости. Проект включает в себя полный ML pipeline с использованием методов машинного обучения, включая генерацию признаков, отбор признаков и оптимизацию гиперпараметров.

### Цели проекта
- Улучшить метрики качества baseline-модели
- Создать воспроизводимый ML pipeline
- Интегрировать MLflow для отслеживания экспериментов
- Зарегистрировать все версии моделей в MLflow Model Registry

### Используемые технологии
- **Python 3.10+**
- **Scikit-learn** - для предобработки данных и создания pipeline
- **CatBoost** - основная модель машинного обучения
- **MLflow** - для отслеживания экспериментов и управления моделями
- **MLXTEND** - для отбора признаков
- **Optuna** - для оптимизации гиперпараметров
- **AutoFeat** - для автоматической генерации признаков
- **Pandas, NumPy** - для работы с данными
- **Matplotlib, Seaborn** - для визуализации

## Установка и запуск

### Предварительные требования
- Python 3.10+
- Git
- Доступ к S3 хранилищу

### Установка зависимостей

```bash
# Клонирование репозитория
git clone <ссылка-на-ваш-репозиторий>
cd mle-project-sprint-2-v001

# Установка зависимостей
pip install -r requirements.txt
```

### Настройка окружения

1. Создайте файл `.env` в корне проекта с настройками:
```bash
MLFLOW_TRACKING_HOST=127.0.0.1
MLFLOW_TRACKING_PORT=5000
MLFLOW_S3_ENDPOINT_URL=<ваш-s3-endpoint>
AWS_ACCESS_KEY_ID=<ваш-access-key>
AWS_SECRET_ACCESS_KEY=<ваш-secret-key>
```

2. Запустите MLflow сервисы:
```bash
chmod +x mlflow_server/rms.sh
./mlflow_server/rms.sh
```

3. Запустите Jupyter Notebook:
```bash
jupyter notebook model_improvement/project_sprint_2.ipynb
```

## Руководство по проекту

Проект состоит из 5 этапов, каждый из которых логируется в MLflow:

### Этап 1: Разворачивание MLflow и регистрация модели

**Описание:** Настройка MLflow Tracking Server и MLflow Model Registry, регистрация базовой модели.

**Команды для запуска:**
```bash
# Запуск MLflow сервисов
bash rms.sh
```

**MLflow эксперимент:**
- **ID:** 2
- **Название:** baseline_model_improvement_REPP

**S3 Bucket:** `s3-student-mle-20220720-8e1t9t3775`

### Этап 2: Проведение EDA

**Описание:** Исследовательский анализ данных с визуализацией и статистическим анализом.

**Ключевые выводы EDA:**
1. **Целевая переменная (price):** Сильно скошена вправо, требует логарифмического преобразования
2. **Корреляции:** Высокая корреляция между площадями (total_area, living_area, kitchen_area)
3. **Выбросы:** Обнаружены аномальные значения в площади и количестве комнат

**MLflow запуски:**
- `stage_2_eda` - логирование результатов EDA

### Этап 3: Генерация признаков и обучение модели

**Описание:** Создание новых признаков с помощью sklearn.preprocessing и AutoFeat.

**Методы генерации признаков:**
- **RobustScaler** - масштабирование признаков
- **KBinsDiscretizer** - дискретизация числовых признаков
- **PolynomialFeatures** - создание полиномиальных признаков
- **AutoFeat** - автоматическая генерация признаков

**Результаты:**
- Исходно: 15 признаков
- После генерации: 517 признаков
- Увеличение в 34.5 раза

**MLflow запуски:**
- `stage_3_feature_engineering` - логирование процесса генерации признаков

### Этап 4: Отбор признаков и обучение новой версии модели

**Описание:** Использование методов отбора признаков для определения наиболее важных.

**Методы отбора:**
- **Forward Selection** - последовательный отбор признаков вперед
- **Backward Selection** - последовательный отбор признаков назад
- **Intersection vs Union** - выбор между пересечением и объединением

**Результаты:**
- Исходно: 517 признаков
- Отобрано: 6 признаков
- Сокращение: 98.8%
- Выбранные признаки: rs__floor, rs__kitchen_area, rs__living_area, rs__rooms, rs__total_area, и один дополнительный

**MLflow запуски:**
- `stage_4_feature_selection` - логирование процесса отбора признаков

### Этап 5: Подбор гиперпараметров и обучение новой версии модели

**Описание:** Оптимизация гиперпараметров модели с использованием двух методов.

**Методы оптимизации:**
1. **HalvingRandomSearchCV** - случайный поиск с последовательным сокращением
2. **Optuna** - байесовская оптимизация с MLflowCallback

**Оптимальные параметры:**
- learning_rate: 0.059963338824126605
- depth: 8
- iterations: 544
- l2_leaf_reg: 2.763845761772307
- min_data_in_leaf: 1
- max_ctr_complexity: 3

**MLflow запуски:**
- `stage_5_hyperparameter_tuning` - логирование процесса оптимизации
- `stage_5_final_model` - логирование финальной модели

## Результаты проекта

### Метрики качества

| Метрика | Baseline | Финальная модель | Изменение |
|---------|----------|------------------|-----------|
| RMSE | 4,157,670.131 ₽ | 4,678,509.352 ₽ | -12.5% |
| R² | 0.880 | 0.851 | -3.3% |
| MAE | - | 2,553,921 ₽ | - |

### Анализ результатов

**Проблемы:**
1. **Ухудшение метрик:** Финальная модель показала худшие результаты по сравнению с baseline
2. **Переобучение:** Возможно, модель переобучилась на обучающих данных
3. **Недостаточная генерация признаков:** AutoFeat мог создать избыточные признаки

**Возможные причины:**
- Слишком агрессивный отбор признаков (98.8% сокращение)
- Неоптимальные гиперпараметры
- Недостаточная валидация на кросс-валидации

## Заключение

Проект успешно выполнен с точки зрения технических требований:
- ✅ Все 5 этапов реализованы
- ✅ MLflow интегрирован и настроен
- ✅ 4 версии моделей зарегистрированы в Model Registry
- ✅ Все эксперименты логируются
- ✅ Код структурирован и документирован

Однако результаты показывают необходимость дальнейшей оптимизации:
- Требуется пересмотр стратегии отбора признаков
- Необходима более тщательная валидация
- Возможно, стоит рассмотреть другие алгоритмы машинного обучения
