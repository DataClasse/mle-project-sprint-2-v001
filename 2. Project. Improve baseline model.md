# Проект. Улучшение baseline-модели

## Описание задачи

Напомним, что вы работаете в Яндекс Недвижимости, маркетплейсе для аренды и покупки жилой и коммерческой недвижимости. Ваша задача — выступить надёжным посредником между арендодателями или продавцами и потенциальными арендаторами или покупателями, сделав процесс сделки максимально эффективным и безопасным для обеих сторон.

#### **Проблема**

Вы выдвинули гипотезу, что стоимость объекта недвижимости можно объективно оценить извне — это устранит разногласия между сторонами и увеличит среднемесячное количество сделок на платформе. Вы разработали базовое решение в виде модели машинного обучения, а также организовали пайплайн данных в Airflow. Менеджеры убедились, что ваша модель потенциально прибыльна, однако вместе с тем сделали вывод, что метрики модели можно улучшить.

## Бизнес-задача

Вам нужно оптимизировать подход, основываясь на первоначально построенном решении и настроенном пайплайне данных. Ваша цель — сделать процесс воспроизводимым и улучшить ключевые модельные метрики, которые влияют на бизнес-показатели компании, в частности, на увеличение количества успешных сделок. Чтобы провести большое число экспериментов и обеспечить их воспроизводимость, для начала интегрируйте MLflow.

## Задача машинного обучения

Процесс прогнозирования стоимости требует доработки. Вы будете использовать методы конструирования и отбора признаков, а также применять алгоритмы для поиска оптимальных гиперпараметров модели.

Вам нужно улучшить основную метрику проекта, которая влияет на точность предсказаний стоимости недвижимости и, как следствие, на количество успешных сделок на маркетплейсе. В процессе работы документируйте все эксперименты, используя MLflow, — это позволит вам отслеживать изменения в метриках и вносимые улучшения. Все успешные версии моделей должны быть зарегистрированы в соответствующем реестре MLflow, чтобы вы могли их отслеживать, сравнивать и использовать впоследствии. Так вы не только систематизируете процесс разработки и оценки моделей, но и обеспечите воспроизводимость результатов.

#### **Данные**

Чтобы улучшить модель прогнозирования стоимости, вы будете работать с данными, подготовленными и предобработанными с помощью пайплайна в Airflow. Пользуйтесь теми данными, на которых уже обучалась модель.

#### **Инфраструктура и инструменты**

Для выполнения проекта вам понадобятся следующие инструменты:

- Visual Studio Code,
- Jupyter Notebook,
- база данных PostgreSQL с данными для обучения,
- база данных PostgreSQL с данными для MLflow,
- объектное хранилище для MLflow,
- сервисы MLflow (Tracking Server и Model Registry),
- библиотеки, которые вы изучили в рамках спринта.

Помимо этого, мы рекомендуем использовать виртуальную машину для проведения всех этапов.

#### **Инструкция по выполнению проекта**

Все шаги разработки и исполнения кода выполняйте на виртуальной машине, обращаясь к персональной базе данных, а также используйте облачное хранилище S3.

**Важно:** все задания в Jupyter Notebook выполняйте в **одном** файле. Шаблон блокнота вы найдёте в папке `model_improvement`. Сдать его на проверку нужно будет в следующем уроке «Загрузка Jupyter Notebook».

Запустите виртуальную машину, когда будете готовы приступить к выполнению проекта.

#### **Этап 1. Разворачивание MLflow Tracking Server и MLflow Model Registry. Регистрация существующей модели**

На этом этапе проекта вы развернёте сервисы MLflow Tracking Server и MLflow Model Registry, используя базу данных PostgreSQL и объектное хранилище S3 в Yandex Cloud. Всё для того, чтобы в дальнейшем вы могли логировать, отслеживать и управлять вашими экспериментами и моделями машинного обучения. Для этого:

1. Поднимите Tracking Server и Model Registry**,** настроив окружение с переменными для S3 (`MLFLOW_S3_ENDPOINT_URL`, `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`), и запустите MLflow-сервер с указанием PostgreSQL в качестве `backend-store-uri` и S3 в качестве `default-artifact-root`.
2. Возьмите вашу обученную модель из предыдущего спринта, а также данные, на которых она обучалась, и метрики тестовой выборки. Зарегистрируйте её в MLflow, указав сигнатуру. Не забудьте про логирование необходимых параметров, метрик и артефактов.

**Результаты этапа:**

1. Shell-скрипт для запуска MLflow-сервисов и код для регистрации модели. Сюда же входят залогированные параметры, метрики на тестовой выборке, окружение и артефакты, сохранённые в вашем репозитории на GitHub. Скрипты должны находиться в директории `mlflow_server`, которая уже есть в вашем репозитории.
2. Сохранённая в MLflow Model Registry базовая модель.
3. Инструкция по поднятию MLflow-сервисов и регистрации модели в MLflow Tracking Server в файле `Readme`. Все детали мы описали в уроке «**Как сдать проект**».

#### **Этап 2. Проведение исследовательского анализа данных и логирование Jupyter Notebook с EDA в MLflow**

На этом этапе вы проведёте исследовательский анализ данных (EDA), чтобы лучше понять их характеристики и взаимосвязи. Вам предстоит:

1. Загрузить данные в Jupyter Notebook, используя библиотеку `pandas`. Убедитесь, что вы провели предварительную обработку данных, затронув пропущенные значения и преобразование типов данных.
2. Визуализировать данные, построив графики при помощи библиотек `Matplotlib` и `Seaborn`, — так вы наглядно представите распределение признаков, в том числе целевую переменную.
3. Проанализировать взаимодействие признаков и целевой переменной, используя статистические методы и визуализацию.
4. Создать ячейку в формате `Markdown`, в которой будут описаны минимум три ключевых вывода, полученных в ходе EDA. Эти выводы должны касаться важных особенностей данных, которые могут повлиять на выбор модели или стратегии моделирования. Например, интересные корреляции, закономерности или аномалии.
5. Залогировать в MLflow в качестве артефактов ваши Jupyter Notebook и `Markdown`-файл с выводами, используя MLflow Python API. Выводы после EDA возьмите из ячейки, которую вы сформировали ранее. Это позволит вам отслеживать и сравнивать различные EDA, проведённые в ходе проекта.

**Результаты этапа:**

1. Оформленный раздел в Jupyter Notebook с EDA, который включает ваш код, созданные графики и комментарии к каждому шагу анализа.
2. Ячейка в формате `Markdown` в Jupyter Notebook с выводами.
3. Залогированные в MLflow Jupyter Notebook и `Markdown`-файл с выводами как артефакты.

#### **Этап 3. Генерация признаков и обучение модели**

На этом этапе вы будете улучшать вашу модель с помощью генерации новых признаков. Для этого:

1. Займитесь предобработкой данных. Используйте подходящие методы из `sklearn.preprocessing` для нормализации, масштабирования или кодирования признаков в ваших данных.
2. Сгенерируйте признаки, используя `sklearn.preprocessing`. Примените как минимум два метода: `PolynomialFeatures` — для создания полиномиальных признаков, `KBinsDiscretizer` — для дискретизации числовых признаков. Соберите все преобразования в объект `ColumnTransformer`.
3. Создайте `sklearn`-пайплайн. Интегрируйте ваш `ColumnTransformer` в объект `Pipeline`, чтобы обеспечить последовательную предобработку данных.
4. Настройте автоматическую генерацию признаков с помощью библиотеки `autofeat`.
5. Обучите новую версию модели на обогащённом наборе признаков. Затем оцените её качество и производительность (скорость обучения и предсказаний). Результаты залогируйте в MLflow.
6. Сохраните новую версию модели в MLflow Model Registry.

**Результаты этапа:**

1. Код в Jupyter Notebook для предобработки данных, генерации признаков и создания пайплайна. Убедитесь, что код включает подробные комментарии к каждому шагу.
2. Оформленный раздел в Jupyter Notebook с примерами использования `autofeat` для автоматической генерации признаков.
3. Залогированные в MLflow: `Pipeline`, код для генерации признаков, окружение, сигнатура модели и сама обученная модель.
4. Новая версия модели в MLflow Model Registry.

#### **Этап 4. Отбор признаков и обучение новой версии модели**

На этом этапе вы будете использовать ранее обогащённые данные и примените методы отбора признаков, чтобы определить наиболее важные — так вы повысите производительность модели. Для этого:

1. Используйте как минимум два метода отбора из библиотеки `mlxtend`, например, `backward feature selection` и `forward feature selection`, чтобы определить наиболее значимые признаки для вашей модели.
2. Обучите новую версию модели на основе отобранных признаков, а затем оцените её метрики на тестовой выборке.
3. Используйте MLflow Python API, чтобы залогировать процесс отбора признаков, окружение, обученную модель, её параметры, метрики качества и другие артефакты. Сюда также должны входить графики важности признаков и метрики модели после отбора признаков на тестовой выборке.
4. Сохраните новую версию модели в MLflow Model Registry.

**Результаты этапа:**

1. Код для отбора признаков и обучения модели, оформленный и сохранённый внутри Jupyter Notebook. Убедитесь, что код включает подробные комментарии к каждому шагу.
2. Залогированные артефакты в MLflow.
3. Новая версия модели в MLflow Model Registry.

#### **Этап 5. Подбор гиперпараметров и обучение новой версии модели**

На заключительном этапе проекта вы сосредоточитесь на оптимизации гиперпараметров модели. Вы будете использовать минимум два метода, один из которых вы реализуете с помощью библиотеки `optuna`. Для этого:

1. Подберите гиперпараметры, используя `optuna`. Залогируйте процесс их оптимизации, их значения и метрики качества с помощью MLflow Callback.
2. Примените второй метод оптимизации. Это может быть ещё один алгоритм из библиотеки `optuna` или Random Search, Grid Search, `HalvingGridSearchCV` из `sklearn`. Попутно логируйте процесс и результаты в MLflow.
3. Обучите новую версию модели, используя отобранные признаки и лучшие гиперпараметры. Оцените её производительность на тестовой выборке и сравните с предыдущими версиями моделей.
4. Финальную модель, её метрики и дополнительные артефакты также залогируйте в MLflow, а модель зарегистрируйте в MLflow Model Registry с новой версией. Укажите применённые методы оптимизации гиперпараметров и достигнутые улучшения.

**Результаты этапа:**

1. Код для подбора гиперпараметров и обучения модели, оформленный и сохранённый внутри Jupyter Notebook. Не забудьте про подробные комментарии к каждому этапу работы.
2. Запуски в MLflow: Убедитесь, что весь процесс подбора гиперпараметров, включая эксперименты с разными методами и их результаты, окружение, а также финальные метрики новой версии модели, залогированы в MLflow.
3. Финальная версия модели в MLflow Model Registry.

## Как будут проверять мой проект

Ваш проект будут оценивать по конкретным критериям. Прежде чем решать задачу, внимательно изучите их. Задание считается выполненным, если:

- Имеются как минимум 4 зарегистрированные версии модели в MLflow Model Registry:
    - базовая модель, полученная на предыдущем этапе,
    - модель после генерации признаков,
    - модель после отбора признаков,
    - модель после подбора гиперпараметров.
- Артефакты, код, метрики и параметры модели залогированы в MLflow для каждого этапа проекта — всё в рамках одного эксперимента.
- Код чётко структурирован и хорошо документирован. Есть комментарии к его ключевым блокам, отражающие логику работы.
- Есть оформленный Jupyter Notebook со всеми этапами проекта.
- При работе с признаками (трансформация и генерация новых) используется объект `sklearn.Pipeline`, который также залогирован в MLflow.

В этом уроке вам нужно сдать на проверку репозиторий. На что обращают внимание ревьюеры, при проверке репозитория:

- В репозитории есть актуальная документация, включая `Readme.md` с описанием проекта.
- В репозитории есть `requirements.txt` или `conda.yaml`, отражающие все необходимые зависимости для воспроизведения проекта.
- В репозитории есть shell-скрипт для поднятия MLflow-сервисов.
